{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"engine\": \"google_jobs\",\n",
    "    \"q\": \"Data Engineer | Analytics Engineer\",  # Use the function's query parameter\n",
    "    \"hl\": \"en\",\n",
    "    \"chips\": \"date_posted:week\",\n",
    "    \"api_key\": API_KEY,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the search\n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()\n",
    "jobs_results = results.get(\"jobs_results\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Data Engineer',\n",
       "  'company_name': 'Entergy',\n",
       "  'location': '  Russellville, AR   ',\n",
       "  'via': 'via Entergy Jobs',\n",
       "  'description': 'Data Engineer\\n\\nDate: Mar 13, 2024\\n\\nLocation: Little Rock, Arkansas, United States\\n\\nCompany: Entergy\\n\\nPosting End Date:\\n\\nWork Place Flexibility: Hybrid\\n\\nLegal Entity: Entergy Services, LLC\\n\\nThis posting will be used to fill multiple vacancies. These vacancies can be filled as a Data Engineer I – Data Engineer II depending on related experience.\\n\\nNew Orleans, LA or Little Rock, AR are preferred locations for these roles; However, these positions can be filled in Louisiana, Texas, Mississippi, or Arkansas.\\n\\nJob Summary/Purpose:\\n\\nThe Data Engineer reports to the Manager, Business Services Operations – Meter to Cash, and often works closely with the VP Meter to Cash and VP Contact Center and their teams to help drive continual improvements across Entergy and within Entergy Customer Operations.\\n\\nThis position will: (1) develop, construct, test and maintain architectures, such as databases and large-scale processing systems; (2) analyze and optimize raw data that may contain human, system... errors; (3) recommend ways to improve data reliability, efficiency, and quality by employing a variety of languages and tools to marry systems together or try to hunt down opportunities to acquire new data from other systems to support sound business decisions; (4) ensure that the architecture that is in place supports the requirements of the of Customer Operations stakeholders, and the business; (5) deliver data visualization and insights to Customer Operations stakeholders to drive sound business decision and optimization. (6) Develop data set processes for data modeling, mining, and production.\\n\\nJob Duties/Responsibilities\\n• Analytics\\n• Support the multi-year analytics roadmap to transform how Customer Operations uses data for decision support and process improvement.\\n• Architect, build and publish Customer Operations metrics, analytics, and reporting for inclusion in Customer Operations and business communications.\\n• Extract and aggregate data sets from various sources, including both databases and flat files.\\n• Apply data analytics practices and the right tools (e.g. Power BI, Python, SQL, Hadoop).\\n• Gather requirements, formulate metrics and synthesize analytics into dashboard and reports.\\n• Present data and information, in technical and business terms, with a compelling final product that tells a story to management.\\n• Analyze data sources, taxonomies and methodologies regularly to ensure data integrity from all relevant data sources.\\n• Identify statistically significant patterns, correlations, and compelling questions raised by such analysis.\\n• Data\\n• Develop, construct, test and maintain architectures across Customer Operations including databases, Customer Operations processing systems\\n• Gather, collect, store, and process data the data, leveraging tools and technology including ETL, API, SQL.\\n• Conduct or participate in management of analytical studies to address moderately difficult to complex business problems, identify deficiencies and improve solutions which impact Entergy Custom er Operations effectiveness and provide the basis for management decisions.\\n• Develop, manage and deploy best in practice data collection, data governance, storage and manipulation techniques (extract, transform and load) that ultimately enable Customer Operations business units to unlock additional value from company-held data.\\n• Focus on improving the data integration of current Customer Operations systems of record as well as ensuring the approach adopted is agile enough to ingest additional data streams as they become available.\\n• Understand the strengths and limitations of various data storing, data transformation and data distribution mechanisms and help identify the appropriate data sources, manipulation tools and techniques (including data enrichment/automation) for a particular analytics use case as a function of data quality (including availability) and work collaboratively with other technology and data experts and Customer Operations SMEs to help solve their analytical needs.\\n• Effectively manage relationships and can create rapport with others. Anticipate customer/stakeholder needs and accept ownership.\\n• At all times put safety first, actively promote safety in both the office environment and on-site/off-site visits at Entergy or supplier sites.\\n\\nMinimum Requirements\\n\\nMinimum education required of the position\\n• Bachelor’s degree in a data-centric field (Economics, Computer Science or other science field), Information Systems, Information Processing, Business, or Engineering.\\n• Master’s in Analytics or related advanced degree preferred.\\n\\nMinimum experience required of the position\\n\\nData Engineer I:\\n• 0-1 years of professional experience with a bachelor’s degree; in lieu of a degree 4 years of experience in data engineering/data modeling is required\\n• At least 2 years in developing and utilizing tools that prepare, extract and manipulate (big) data to create connected datasets (data lake) that can be utilized for analytics purposes preferred.\\n\\nData Engineer II:\\n• 2-4 years of professional experience with a bachelor’s degree in lieu of a degree 6 years of experience in data engineering/data modeling is required\\n• At least 4 years in developing and utilizing tools that prepare, extract and manipulate (big) data to create connected datasets (data lake) that can be utilized for analytics purposes preferred.\\n\\nMinimum knowledge, skills, and abilities required of the position\\n\\nTechnical:\\n• Understanding of gathering requirements, formulate metrics and convert data analysis into tangible reporting products.\\n• Ability to execute in report design, data visualization and presentation techniques.\\n• Solid application of data management, control and data mining applications and systems.\\n• Proficient at providing data driven insights and key recommendations on findings.\\n• Proficient at sharing key insights with department staff and analytics team to promote continuous learning.\\n• Knowledge and understanding of existing and evolving Customer systems.\\n• Works to identify the need for new systems and offers strategic input on the utilization of current systems.\\n\\nProfessional\\n• Knowledge to advise on the application of project management principles to ensure systematic, thorough completion of assignments, identifying critical pathways and risks to delivery.\\n• Ability to communicate with Customer Operations stakeholders, delivering key messages concisely, supported by relevant data; influencing skills to develop best outcomes.\\n• Continually seeks sources of business intelligence on company imperatives, industry trends and emerging capabilities that will drive a world-class customer experience.\\n• Proficient at building extensive relationships and effective networks with all stakeholders.\\n\\nLeadership\\n• Basic skills to influence others to action, and to successfully implement strategies and process improvements\\n• Basic knowledge of change management and continuous improvement methods, and the application to daily activities to drive performance improvement.\\n• Able to provide direction on appropriate change to enable business objectives and ensures consistent application across all initiatives and stakeholder interactions.\\n• Ability to communicate complex scenarios and data, clearly articulate the organization’s strategy, and translate organizational strategy into departmental strategies and plans\\n• Able to provide technical and professional coaching/mentoring on contract provisions, commercial analytics, etc., to project teams, other Customer Operations personnel and Entergy customers.\\n• Ability to lead others through ambiguity and support functional leadership of small teams.\\n• Capability to be the trusted advisor; leader/coach in identifying what is important to the customer base.\\n\\n#LI-RM1\\n\\n#LI-HYBRID\\n\\nPrimary Location: Arkansas-Little Rock Arkansas : Alexander || Arkansas : Arkadelphia || Arkansas : Bald Knob || Arkansas : Batesville || Arkansas : Beebe || Arkansas : Benton || Arkansas : Berryville || Arkansas : Blytheville || Arkansas : Blythville || Arkansas : Brinkley || Arkansas : Cabot || Arkansas : Camden || Arkansas : Clarenden || Arkansas : Conway || Arkansas : Corning || Arkansas : Crossett || Arkansas : DERMONTT || Arkansas : Danville || Arkansas : Dardanelle || Arkansas : Des Arc || Arkansas : Dewitt || Arkansas : Dumas || Arkansas : Earle || Arkansas : El Dorado || Arkansas : Elaine || Arkansas : England || Arkansas : Eudora || Arkansas : Flippin || Arkansas : Fordyce || Arkansas : Forrest City || Arkansas : Glenwood || Arkansas : Gurdon || Arkansas : Hamburg || Arkansas : Hardy || Arkansas : Harrisburg || Arkansas : Harrison || Arkansas : Hazen || Arkansas : Heber Springs || Arkansas : Helena || Arkansas : Hot Springs || Arkansas : Hotsprings || Arkansas : Hoxie || Arkansas : Hughes || Arkansas : Jacksonville || Arkansas : Jones Mill || Arkansas : Junction City || Arkansas : Lake Village || Arkansas : Little Rock || Arkansas : Lonoke || Arkansas : Magnolia || Arkansas : Malvern || Arkansas : Mammoth Sprgs || Arkansas : Marianna || Arkansas : Marion || Arkansas : Marked Tree || Arkansas : Marshall || Arkansas : Maumelle || Arkansas : Mcgehee || Arkansas : Monette || Arkansas : Monticello || Arkansas : Morrilton || Arkansas : Mountain Home || Arkansas : Mountain View || Arkansas : Newark || Arkansas : Newport || Arkansas : No. Little Rock || Arkansas : Pine Bluff || Arkansas : Pocahontas || Arkansas : Rector || Arkansas : Redfield || Arkansas : Russellville || Arkansas : Searcy || Arkansas : Sheridan || Arkansas : Smackover || Arkansas : Stamps || Arkansas : Stephens || Arkansas : Strong || Arkansas : Stuttgart || Arkansas : Trumann || Arkansas : Warren || Arkansas : West Helena || Arkansas : Wilson || Arkansas : Wynne || Arkansas : Yellville || Louisiana : Amite || Louisiana : Arcadia || Louisiana : Bastrop || Louisiana : Baton Rouge || Louisiana : Belle Chase || Louisiana : Bogalusa || Louisiana : Broussard || Louisiana : Buras || Louisiana : Chalmette || Louisiana : Church Point || Louisiana : DESTREHAN || Louisiana : Delhi || Louisiana : Denham Springs || Louisiana : Donaldsonville || Louisiana : Dubach || Louisiana : Eunice || Louisiana : Ferriday || Louisiana : Fort Polk || Louisiana : Gonzales || Louisiana : Grayson || Louisiana : Gretna || Louisiana : Hammond || Louisiana : Haynesville || Louisiana : Hodge || Louisiana : Homer || Louisiana : Houma || Louisiana : Jefferson || Louisiana : Jena || Louisiana : Jennings || Louisiana : Jonesboro || Louisiana : Joyce || Louisiana : Kenner || Louisiana : Killona || Louisiana : Labadieville || Louisiana : Lafayette || Louisiana : Lake Charles || Louisiana : Lake Providence || Louisiana : Lockport || Louisiana : Luling || Louisiana : Marksville || Louisiana : Metairie || Louisiana : Monroe || Louisiana : Montgomery || Louisiana : Montz || Louisiana : New Orleans || Louisiana : Newellton || Louisiana : Oak Grove || Louisiana : Port Allen || Louisiana : Rayville || Louisiana : Reserve || Louisiana : Ringgold || Louisiana : Saint Rose || Louisiana : Scott || Louisiana : Sibley || Louisiana : Springhill || Louisiana : St. Francisville || Louisiana : St. Gabriel || Louisiana : St. Joseph || Louisiana : St. Rose || Louisiana : Sterlington || Louisiana : Sulphur || Louisiana : Tallulah || Louisiana : Thibodaux || Louisiana : West Monroe || Louisiana : Westlake || Louisiana : Westwego || Louisiana : Winnsboro || Louisiana : Zachary || Mississippi : Belzoni || Mississippi : Brookhaven || Mississippi : CARTHAGE || Mississippi : Canton || Mississippi : Centerville || Mississippi : Charleston || Mississippi : Clarksdale || Mississippi : Cleveland || Mississippi : Clinton || Mississippi : Crystal Springs || Mississippi : Drew || Mississippi : Fayette || Mississippi : Flora || Mississippi : French Camp || Mississippi : Gloster || Mississippi : Greenville || Mississippi : Greenwood || Mississippi : Grenada || Mississippi : Hazlehurst || Mississippi : Hernando || Mississippi : Hollandale || Mississippi : Indianola || Mississippi : Jackson || Mississippi : Kosciusko || Mississippi : Lexington || Mississippi : Madison || Mississippi : Magee || Mississippi : Marks || Mississippi : Mccomb || Mississippi : Meadville || Mississippi : Mendenhall || Mississippi : Morton || Mississippi : Natchez || Mississippi : Nesbit || Mississippi : Pearl || Mississippi : Port Gibson || Mississippi : Prentiss || Mississippi : Ridgeland || Mississippi : Rolling Fork || Mississippi : Rosedale || Mississippi : Sallis || Mississippi : Sardis || Mississippi : Senatobia || Mississippi : Shelby || Mississippi : Southaven || Mississippi : Summer || Mississippi : Tunica || Mississippi : Tylertown || Mississippi : Vicksburg || Mississippi : Winona || Mississippi : Woodville || Mississippi : Yazoo City || Texas : Anahuac || Texas : Austin || Texas : Beaumont || Texas : Burkeville || Texas : Calvert || Texas : Cleveland || Texas : Conroe || Texas : Corpus Christi || Texas : Corrigan || Texas : Crystal Beach || Texas : Dayton || Texas : Groveton || Texas : Houston || Texas : Huntsville || Texas : Kountze || Texas : Madisonville || Texas : Marshall || Texas : Navasota || Texas : New Caney || Texas : Orange || Texas : Port Arthur || Texas : Port Neches || Texas : Silsbee || Texas : Somerville || Texas : Sour Lake || Texas : The Woodlands || Texas : Trinity || Texas : Vidor || Texas : Willis || Texas : Winnie || Texas : Woodlands || Texas : Woodville\\n\\nJob Function : Engineering\\n\\nFLSA Status : Professional\\n\\nRelocation Option: No Relocation Offered\\n\\nUnion description/code : NON BARGAINING UNIT\\n\\nNumber of Openings : 1\\n\\nReq ID: 114257\\n\\nTravel Percentage :Up to 25%\\n\\nAn Equal Opportunity Employer, Minority/Female/Disability/Vets. Please clickhere (https://jobs.entergy.com/content/EEO/?locale=en_US) to view the EEI page, or see statements below.\\n\\nEEO Statement: The Entergy System of Companies provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a protected veteran in accordance with applicable federal, state and local laws. The Entergy System of Companies complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment including, but not limited to, recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.\\n\\nThe Entergy System of Companies expressly prohibits any form of unlawful employee harassment based on race, color, religion, sex, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of the Entergy System of Company employees to perform their expected job duties is absolutely not tolerated.\\n\\nAccessibility: Entergy provides reasonable accommodations for online applicants. Requests for a reasonable accommodation may be made orally or in writing by an applicant, employee, or third party on his or her behalf. If you are an individual with a disability and you are in need of an accommodation for the recruiting process please click here (humanr@entergy.com?subject=Accessibility) and provide your name, contact number, the accommodation requested and the requisition number that you are requesting the accommodation for. Employee Services will contact you regarding your request.\\n\\nAdditional Responsibilities: As a provider of essential services, Entergy expects its employees to be available to work additional hours, to work in alternate locations, and/or to perform additional duties in connection with storms, outages, emergencies, or other situations as deemed necessary by the company. Exempt employees may not be paid overtime associated with such duties.\\n\\nEntergy Pay Transparency Policy Statement: The Entergy System of Companies (the Company) will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company’s legal duty to furnish information. 41 CFR 60-1.35(c). Equal Opportunity (https://www.dol.gov/agencies/ofccp/manual/fccm/2l-equal-opportunity-clauses-and-other-requirements/2l00-equal-opportunity) and Pay Transparency (https://www.dol.gov/sites/dolgov/files/OFCCP/pdf/pay-transp_%20English_formattedESQA508c.pdf) .\\n\\nPay Transparency Notice:\\n\\nPay Transparency Nondiscrimination Provision (dol.gov) (https://www.dol.gov/sites/dolgov/files/ofccp/pdf/pay-transp_%20English_formattedESQA508c.pdf)\\n\\nThe non-confidential portions of the affirmative action program for individuals with disabilities and protected veterans shall be available for inspection upon request by any employee or applicant for employment. Please contact HRCompliance@entergy.com to schedule a time to review the affirmative action plan during regular office hours.\\n\\nWORKING CONDITIONS:\\n\\nAs a provider of essential services, Entergy expects its employees to be available to work additional hours, to work in alternate locations, and/or to perform additional duties in connection with storms, outages, emergencies, or other situations as deemed necessary by the company. Exempt employees may not be paid overtime associated with such duties.\\n\\nPlease note: Authorization to work in the United States is a precondition to employment in this position. Entergy will not sponsor candidates for work visas for this position.\\n\\nJob Segment: Developer, Data Modeler, Engineer, Database, SQL, Technology, Data, Engineering',\n",
       "  'job_highlights': [{'items': ['Data Engineer\\n\\nDate: Mar 13, 2024\\n\\nLocation: Little Rock, Arkansas, United States\\n\\nCompany: Entergy\\n\\nPosting End Date:\\n\\nWork Place Flexibility: Hybrid\\n\\nLegal Entity: Entergy Services, LLC\\n\\nThis posting will be used to fill multiple vacancies. These vacancies can be filled as a Data Engineer I – Data Engineer II depending on related experience.\\n\\nNew Orleans, LA or Little Rock, AR are preferred locations for these roles; However, these positions can be filled in Louisiana, Texas, Mississippi, or Arkansas.\\n\\nJob Summary/Purpose:\\n\\nThe Data Engineer reports to the Manager, Business Services Operations – Meter to Cash, and often works closely with the VP Meter to Cash and VP Contact Center and their teams to help drive continual improvements across Entergy and within Entergy Customer Operations.\\n\\nThis position will: (1) develop, construct, test and maintain architectures, such as databases and large-scale processing systems; (2) analyze and optimize raw data that may contain human, system... errors; (3) recommend ways to improve data reliability, efficiency, and quality by employing a variety of languages and tools to marry systems together or try to hunt down opportunities to acquire new data from other systems to support sound business decisions; (4) ensure that the architecture that is in place supports the requirements of the of Customer Operations stakeholders, and the business; (5) deliver data visualization and insights to Customer Operations stakeholders to drive sound business decision and optimization. (6) Develop data set processes for data modeling, mining, and production.\\n\\nJob Duties/Responsibilities\\n• Analytics\\n• Support the multi-year analytics roadmap to transform how Customer Operations uses data for decision support and process improvement.\\n• Architect, build and publish Customer Operations metrics, analytics, and reporting for inclusion in Customer Operations and business communications.\\n• Extract and aggregate data sets from various sources, including both databases and flat files.\\n• Apply data analytics practices and the right tools (e.g. Power BI, Python, SQL, Hadoop).\\n• Gather requirements, formulate metrics and synthesize analytics into dashboard and reports.\\n• Present data and information, in technical and business terms, with a compelling final product that tells a story to management.\\n• Analyze data sources, taxonomies and methodologies regularly to ensure data integrity from all relevant data sources.\\n• Identify statistically significant patterns, correlations, and compelling questions raised by such analysis.\\n• Data\\n• Develop, construct, test and maintain architectures across Customer Operations including databases, Customer Operations processing systems\\n• Gather, collect, store, and process data the data, leveraging tools and technology including ETL, API, SQL.\\n• Conduct or participate in management of analytical studies to address moderately difficult to complex business problems, identify deficiencies and improve solutions which impact Entergy Custom er Operations effectiveness and provide the basis for management decisions.\\n• Develop, manage and deploy best in practice data collection, data governance, storage and manipulation techniques (extract, transform and load) that ultimately enable Customer Operations business units to unlock additional value from company-held data.\\n• Focus on improving the data integration of current Customer Operations systems of record as well as ensuring the approach adopted is agile enough to ingest additional data streams as they become available.\\n• Understand the strengths and limitations of various data storing, data transformation and data distribution mechanisms and help identify the appropriate data sources, manipulation tools and techniques (including data enrichment/automation) for a particular analytics use case as a function of data quality (including availability) and work collaboratively with other technology and data experts and Customer Operations SMEs to help solve their analytical needs.\\n• Effectively manage relationships and can create rapport with others. Anticipate customer/stakeholder needs and accept ownership.\\n• At all times put safety first, actively promote safety in both the office environment and on-site/off-site visits at Entergy or supplier sites.\\n\\nMinimum Requirements\\n\\nMinimum education required of the position\\n• Bachelor’s degree in a data-centric field (Economics, Computer Science or other science field), Information Systems, Information Processing, Business, or Engineering.\\n• Master’s in Analytics or related advanced degree preferred.\\n\\nMinimum experience required of the position\\n\\nData Engineer I:\\n• 0-1 years of professional experience with a bachelor’s degree; in lieu of a degree 4 years of experience in data engineering/data modeling is required\\n• At least 2 years in developing and utilizing tools that prepare, extract and manipulate (big) data to create connected datasets (data lake) that can be utilized for analytics purposes preferred.\\n\\nData Engineer II:\\n• 2-4 years of professional experience with a bachelor’s degree in lieu of a degree 6 years of experience in data engineering/data modeling is required\\n• At least 4 years in developing and utilizing tools that prepare, extract and manipulate (big) data to create connected datasets (data lake) that can be utilized for analytics purposes preferred.\\n\\nMinimum knowledge, skills, and abilities required of the position\\n\\nTechnical:\\n• Understanding of gathering requirements, formulate metrics and convert data analysis into tangible reporting products.\\n• Ability to execute in report design, data visualization and presentation techniques.\\n• Solid application of data management, control and data mining applications and systems.\\n• Proficient at providing data driven insights and key recommendations on findings.\\n• Proficient at sharing key insights with department staff and analytics team to promote continuous learning.\\n• Knowledge and understanding of existing and evolving Customer systems.\\n• Works to identify the need for new systems and offers strategic input on the utilization of current systems.\\n\\nProfessional\\n• Knowledge to advise on the application of project management principles to ensure systematic, thorough completion of assignments, identifying critical pathways and risks to delivery.\\n• Ability to communicate with Customer Operations stakeholders, delivering key messages concisely, supported by relevant data; influencing skills to develop best outcomes.\\n• Continually seeks sources of business intelligence on company imperatives, industry trends and emerging capabilities that will drive a world-class customer experience.\\n• Proficient at building extensive relationships and effective networks with all stakeholders.\\n\\nLeadership\\n• Basic skills to influence others to action, and to successfully implement strategies and process improvements\\n• Basic knowledge of change management and continuous improvement methods, and the application to daily activities to drive performance improvement.\\n• Able to provide direction on appropriate change to enable business objectives and ensures consistent application across all initiatives and stakeholder interactions.\\n• Ability to communicate complex scenarios and data, clearly articulate the organization’s strategy, and translate organizational strategy into departmental strategies and plans\\n• Able to provide technical and professional coaching/mentoring on contract provisions, commercial analytics, etc., to project teams, other Customer Operations personnel and Entergy customers.\\n• Ability to lead others through ambiguity and support functional leadership of small teams.\\n• Capability to be the trusted advisor; leader/coach in identifying what is important to the customer base.\\n\\n#LI-RM1\\n\\n#LI-HYBRID\\n\\nPrimary Location: Arkansas-Little Rock Arkansas : Alexander || Arkansas : Arkadelphia || Arkansas : Bald Knob || Arkansas : Batesville || Arkansas : Beebe || Arkansas : Benton || Arkansas : Berryville || Arkansas : Blytheville || Arkansas : Blythville || Arkansas : Brinkley || Arkansas : Cabot || Arkansas : Camden || Arkansas : Clarenden || Arkansas : Conway || Arkansas : Corning || Arkansas : Crossett || Arkansas : DERMONTT || Arkansas : Danville || Arkansas : Dardanelle || Arkansas : Des Arc || Arkansas : Dewitt || Arkansas : Dumas || Arkansas : Earle || Arkansas : El Dorado || Arkansas : Elaine || Arkansas : England || Arkansas : Eudora || Arkansas : Flippin || Arkansas : Fordyce || Arkansas : Forrest City || Arkansas : Glenwood || Arkansas : Gurdon || Arkansas : Hamburg || Arkansas : Hardy || Arkansas : Harrisburg || Arkansas : Harrison || Arkansas : Hazen || Arkansas : Heber Springs || Arkansas : Helena || Arkansas : Hot Springs || Arkansas : Hotsprings || Arkansas : Hoxie || Arkansas : Hughes || Arkansas : Jacksonville || Arkansas : Jones Mill || Arkansas : Junction City || Arkansas : Lake Village || Arkansas : Little Rock || Arkansas : Lonoke || Arkansas : Magnolia || Arkansas : Malvern || Arkansas : Mammoth Sprgs || Arkansas : Marianna || Arkansas : Marion || Arkansas : Marked Tree || Arkansas : Marshall || Arkansas : Maumelle || Arkansas : Mcgehee || Arkansas : Monette || Arkansas : Monticello || Arkansas : Morrilton || Arkansas : Mountain Home || Arkansas : Mountain View || Arkansas : Newark || Arkansas : Newport || Arkansas : No. Little Rock || Arkansas : Pine Bluff || Arkansas : Pocahontas || Arkansas : Rector || Arkansas : Redfield || Arkansas : Russellville || Arkansas : Searcy || Arkansas : Sheridan || Arkansas : Smackover || Arkansas : Stamps || Arkansas : Stephens || Arkansas : Strong || Arkansas : Stuttgart || Arkansas : Trumann || Arkansas : Warren || Arkansas : West Helena || Arkansas : Wilson || Arkansas : Wynne || Arkansas : Yellville || Louisiana : Amite || Louisiana : Arcadia || Louisiana : Bastrop || Louisiana : Baton Rouge || Louisiana : Belle Chase || Louisiana : Bogalusa || Louisiana : Broussard || Louisiana : Buras || Louisiana : Chalmette || Louisiana : Church Point || Louisiana : DESTREHAN || Louisiana : Delhi || Louisiana : Denham Springs || Louisiana : Donaldsonville || Louisiana : Dubach || Louisiana : Eunice || Louisiana : Ferriday || Louisiana : Fort Polk || Louisiana : Gonzales || Louisiana : Grayson || Louisiana : Gretna || Louisiana : Hammond || Louisiana : Haynesville || Louisiana : Hodge || Louisiana : Homer || Louisiana : Houma || Louisiana : Jefferson || Louisiana : Jena || Louisiana : Jennings || Louisiana : Jonesboro || Louisiana : Joyce || Louisiana : Kenner || Louisiana : Killona || Louisiana : Labadieville || Louisiana : Lafayette || Louisiana : Lake Charles || Louisiana : Lake Providence || Louisiana : Lockport || Louisiana : Luling || Louisiana : Marksville || Louisiana : Metairie || Louisiana : Monroe || Louisiana : Montgomery || Louisiana : Montz || Louisiana : New Orleans || Louisiana : Newellton || Louisiana : Oak Grove || Louisiana : Port Allen || Louisiana : Rayville || Louisiana : Reserve || Louisiana : Ringgold || Louisiana : Saint Rose || Louisiana : Scott || Louisiana : Sibley || Louisiana : Springhill || Louisiana : St. Francisville || Louisiana : St. Gabriel || Louisiana : St. Joseph || Louisiana : St. Rose || Louisiana : Sterlington || Louisiana : Sulphur || Louisiana : Tallulah || Louisiana : Thibodaux || Louisiana : West Monroe || Louisiana : Westlake || Louisiana : Westwego || Louisiana : Winnsboro || Louisiana : Zachary || Mississippi : Belzoni || Mississippi : Brookhaven || Mississippi : CARTHAGE || Mississippi : Canton || Mississippi : Centerville || Mississippi : Charleston || Mississippi : Clarksdale || Mississippi : Cleveland || Mississippi : Clinton || Mississippi : Crystal Springs || Mississippi : Drew || Mississippi : Fayette || Mississippi : Flora || Mississippi : French Camp || Mississippi : Gloster || Mississippi : Greenville || Mississippi : Greenwood || Mississippi : Grenada || Mississippi : Hazlehurst || Mississippi : Hernando || Mississippi : Hollandale || Mississippi : Indianola || Mississippi : Jackson || Mississippi : Kosciusko || Mississippi : Lexington || Mississippi : Madison || Mississippi : Magee || Mississippi : Marks || Mississippi : Mccomb || Mississippi : Meadville || Mississippi : Mendenhall || Mississippi : Morton || Mississippi : Natchez || Mississippi : Nesbit || Mississippi : Pearl || Mississippi : Port Gibson || Mississippi : Prentiss || Mississippi : Ridgeland || Mississippi : Rolling Fork || Mississippi : Rosedale || Mississippi : Sallis || Mississippi : Sardis || Mississippi : Senatobia || Mississippi : Shelby || Mississippi : Southaven || Mississippi : Summer || Mississippi : Tunica || Mississippi : Tylertown || Mississippi : Vicksburg || Mississippi : Winona || Mississippi : Woodville || Mississippi : Yazoo City || Texas : Anahuac || Texas : Austin || Texas : Beaumont || Texas : Burkeville || Texas : Calvert || Texas : Cleveland || Texas : Conroe || Texas : Corpus Christi || Texas : Corrigan || Texas : Crystal Beach || Texas : Dayton || Texas : Groveton || Texas : Houston || Texas : Huntsville || Texas : Kountze || Texas : Madisonville || Texas : Marshall || Texas : Navasota || Texas : New Caney || Texas : Orange || Texas : Port Arthur || Texas : Port Neches || Texas : Silsbee || Texas : Somerville || Texas : Sour Lake || Texas : The Woodlands || Texas : Trinity || Texas : Vidor || Texas : Willis || Texas : Winnie || Texas : Woodlands || Texas : Woodville\\n\\nJob Function : Engineering\\n\\nFLSA Status : Professional\\n\\nRelocation Option: No Relocation Offered\\n\\nUnion description/code : NON BARGAINING UNIT\\n\\nNumber of Openings : 1\\n\\nReq ID: 114257\\n\\nTravel Percentage :Up to 25%\\n\\nAn Equal Opportunity Employer, Minority/Female/Disability/Vets. Please clickhere (https://jobs.entergy.com/content/EEO/?locale=en_US) to view the EEI page, or see statements below.\\n\\nEEO Statement: The Entergy System of Companies provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a protected veteran in accordance with applicable federal, state and local laws. The Entergy System of Companies complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment including, but not limited to, recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.\\n\\nThe Entergy System of Companies expressly prohibits any form of unlawful employee harassment based on race, color, religion, sex, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of the Entergy System of Company employees to perform their expected job duties is absolutely not tolerated.\\n\\nAccessibility: Entergy provides reasonable accommodations for online applicants. Requests for a reasonable accommodation may be made orally or in writing by an applicant, employee, or third party on his or her behalf. If you are an individual with a disability and you are in need of an accommodation for the recruiting process please click here (humanr@entergy.com?subject=Accessibility) and provide your name, contact number, the accommodation requested and the requisition number that you are requesting the accommodation for. Employee Services will contact you regarding your request.\\n\\nAdditional Responsibilities: As a provider of essential services, Entergy expects its employees to be available to work additional hours, to work in alternate locations, and/or to perform additional duties in connection with storms, outages, emergencies, or other situations as deemed necessary by the company. Exempt employees may not be paid overtime associated with such duties.\\n\\nEntergy Pay Transparency Policy Statement: The Entergy System of Companies (the Company) will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company’s legal duty to furnish information. 41 CFR 60-1.35(c). Equal Opportunity (https://www.dol.gov/agencies/ofccp/manual/fccm/2l-equal-opportunity-clauses-and-other-requirements/2l00-equal-opportunity) and Pay Transparency (https://www.dol.gov/sites/dolgov/files/OFCCP/pdf/pay-transp_%20English_formattedESQA508c.pdf) .\\n\\nPay Transparency Notice:\\n\\nPay Transparency Nondiscrimination Provision (dol.gov) (https://www.dol.gov/sites/dolgov/files/ofccp/pdf/pay-transp_%20English_formattedESQA508c.pdf)\\n\\nThe non-confidential portions of the affirmative action program for individuals with disabilities and protected veterans shall be available for inspection upon request by any employee or applicant for employment. Please contact HRCompliance@entergy.com to schedule a time to review the affirmative action plan during regular office hours.\\n\\nWORKING CONDITIONS:\\n\\nAs a provider of essential services, Entergy expects its employees to be available to work additional hours, to work in alternate locations, and/or to perform additional duties in connection with storms, outages, emergencies, or other situations as deemed necessary by the company. Exempt employees may not be paid overtime associated with such duties.\\n\\nPlease note: Authorization to work in the United States is a precondition to employment in this position. Entergy will not sponsor candidates for work visas for this position.\\n\\nJob Segment: Developer, Data Modeler, Engineer, Database, SQL, Technology, Data, Engineering']}],\n",
       "  'related_links': [{'link': 'http://www.entergy.com/', 'text': 'entergy.com'},\n",
       "   {'link': 'https://www.google.com/search?sca_esv=05f85961c74d2d97&q=Entergy&sa=X&ved=0ahUKEwj2wbek__aEAxXhM0QIHR1gAbwQmJACCMYJ',\n",
       "    'text': 'See web results for Entergy'}],\n",
       "  'extensions': ['2 days ago', 'Full-time'],\n",
       "  'detected_extensions': {'posted_at': '2 days ago',\n",
       "   'schedule_type': 'Full-time'},\n",
       "  'job_id': 'eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJCVjR4d0YyeWdCSVE3Qm5zQUFBQUFBPT0iLCJobCI6ImVuIiwiZmMiOiJFb3dDQ3N3QlFVNTFWMmhqYTJoSkxVMVdabVJMVVZCdVZUaGtaMHh5TkhFNWVYbHpWbm8zUWpkMFZHZFZjRGs1TUhKRVEzcHdhRzgwTTJ0RFYwNVpNbVpmUjJ4aFowWk5XVFpWTVZOaFpYWTVjazluZDFCbU9FTlFUVWs0VUc5R1UyWTJTMEl6VWxKb2JtMTNjR2x4TTBOck0yZzNTSFpvUm05WGMxQk1aRVZmWm5FdE5FNUJhbk5oYXpkck9VRnJaVVEzTmxKb1dWQldWMEV4VkhVeWRXcEdZVTlLY1hCSVZYbDFXbUkyZVVGYWJGRkpPWEpKU0ZScmFubEhRM0pOYXpKSE4yeG5WbEZRV21kSE1HNXlTVU5IRWhkYU5rUXdXbUppZVVOUFNHNXJVRWxRYm1ORFJqUkJjeG9pUVZCWWFHMDFZV3RVZGtwNlZWOTRiekpTT0dWYVdVdGpNM2x5VlZNeVRWWXpkdyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiLm5GZzJlYntmb250LXdlaWdodDo1MDB9LkJpNkRkY3tmb250LXdlaWdodDo1MDB9QXBwbHkgb24gRW50ZXJneSBKb2JzIiwibGluayI6Imh0dHBzOi8vam9ic2VhcmNoLmVudGVyZ3kuY29tL3J1c3NlbGx2aWxsZS1hci9kYXRhLWVuZ2luZWVyL0FFMzM0NTIyMjlCRjQyNkRCNjM5OTRCRkM3N0Y1NUNBL2pvYi8/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=='},\n",
       " {'title': 'Data Engineer',\n",
       "  'company_name': 'Insight Global',\n",
       "  'location': '  Bentonville, AR   ',\n",
       "  'via': 'via LinkedIn',\n",
       "  'description': 'This role requires candidates to sit in Bentonville, Arkansas - relocation candidates can sit remotely for the first 6 months before starting a hybrid schedule.\\n\\nDetails: Our Client is looking for a Data Engineer to join their Data Factory team in the Finance Technology organization. This resource will spend 90% of the day hands on developing and building out the pipelines and 10% on morning... scrum calls to plan for the day, discussing updates, and connecting with the business and product teams to understand requirements.\\n\\nRequired Skills:\\n\\n3-6 years of data engineering experience\\n\\nExperience with GCP or Azure\\n\\nCan create and modify SQL queries.\\n\\nComfortable in SQL databases\\n\\nProgramming: Python, spark, pyspark\\n\\nExperience using Airflow for creating scheduling and monitoring workflows\\n\\nBig data on cloud - any cloud platform',\n",
       "  'job_highlights': [{'title': 'Qualifications',\n",
       "    'items': ['3-6 years of data engineering experience',\n",
       "     'Experience with GCP or Azure',\n",
       "     'Can create and modify SQL queries',\n",
       "     'Comfortable in SQL databases',\n",
       "     'Programming: Python, spark, pyspark',\n",
       "     'Experience using Airflow for creating scheduling and monitoring workflows',\n",
       "     'Big data on cloud - any cloud platform']},\n",
       "   {'title': 'Responsibilities',\n",
       "    'items': ['This resource will spend 90% of the day hands on developing and building out the pipelines and 10% on morning scrum calls to plan for the day, discussing updates, and connecting with the business and product teams to understand requirements']}],\n",
       "  'related_links': [{'link': 'http://www.insightglobal.com/',\n",
       "    'text': 'insightglobal.com'},\n",
       "   {'link': 'https://www.google.com/search?sca_esv=05f85961c74d2d97&q=Insight+Global&sa=X&ved=0ahUKEwj2wbek__aEAxXhM0QIHR1gAbwQmJACCI4K',\n",
       "    'text': 'See web results for Insight Global'}],\n",
       "  'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS3NPZVfMWlf1Xobrp_Lh-K5I_QQ6QYxbe8RTgfrJ8&s',\n",
       "  'extensions': ['1 day ago', 'Full-time', 'No degree mentioned'],\n",
       "  'detected_extensions': {'posted_at': '1 day ago',\n",
       "   'schedule_type': 'Full-time'},\n",
       "  'job_id': 'eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJPb01oTGFCQ0YzNmMxRmJEQUFBQUFBPT0iLCJobCI6ImVuIiwiZmMiOiJFcUlDQ3VJQlFVNTFWMmhqYmxSMGFIUTFhMVU0VHpWbWJsUkpPRXRqZEhReU4ySmllRlZVVEcxaldrZDFhVEJoVG5Wb1UyTXhObU5mY1ZwcVMxbGZkVXRuWDFKc1VFOXJOM0JDVEhCVlUwRnRaRE14ZFVwc01UTnVVa0ZzVkZadVZERm1jMlZNUWpSNE9GQkNXbTVZWkZWWWJGVjZlVGRvTW5wblJHSlZUMmhwTTJWM1dXdHhTMGt6WHpkUE5reFRXSEoyZW1Kdk1IbENNWE55UmpsUmJXSm9kVEpDYTI1Qk5HZGpRbXR3V0UxWlRrSm9kMkpuU1hOQlkzcG1lVGRTU0c5WmNEZFBkbmR3YlVSQmJWQnBSMU5MUzNnNVYwVjFZMU51TW5SS1VWSm5XRGxZTTFoeVp4SVhXalpFTUZwaVlubERUMGh1YTFCSlVHNWpRMFkwUVhNYUlrRlFXR2h0TlZsVVdFaGxkbGhWZVVWU1JHbFpNRVJyUTAxSWJsTTVVV3RTV1VFIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMyIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBMaW5rZWRJbiIsImxpbmsiOiJodHRwczovL3d3dy5saW5rZWRpbi5jb20vam9icy92aWV3L2RhdGEtZW5naW5lZXItYXQtaW5zaWdodC1nbG9iYWwtMzg1MzcxMjk1Nz91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19'},\n",
       " {'title': 'Data Engineer III',\n",
       "  'company_name': 'Walmart',\n",
       "  'location': '  Bentonville, AR   ',\n",
       "  'via': 'via Careers.Walmart.com',\n",
       "  'description': \"What you'll do...\\n\\nPosition: Data Engineer III\\n\\nJob Location: 805 SE Moberly Ln, Bentonville, AR 72712\\n\\nDuties: Problem Formulation: Identifies possible options to address the business problems within one's discipline through analytics, big data analytics, and automation. Applied Business Acumen: Supports the development of business cases and recommendations. Owns delivery of project activity and tasks assigned by others. Supports process updates and changes. Solves business issues. Data Governance: Supports the documentation of data governance processes. Supports the implementation of data governance practices. Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function. Data Transformation and Integration: Extracts data from identified databases. Creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques. Develops knowledge of... current data science and analytics trends. Data Source Identification: Supports the understanding of the priority order of requirements and service level agreements. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data. Data Modeling: Analyzes complex data elements, systems, data flows, dependencies, and relationships to contribute to conceptual, physical, and logical data models. Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs. Defines relational tables, primary and foreign keys, and stored procedures to create a data model structure. Evaluates existing data models and physical databases for variances and discrepancies. Develops efficient data flows. Analyzes data-related system integration challenges and proposes appropriate solutions. Creates training documentation and trains end-users on data modeling. Oversees the tasks of less experienced programmers and stipulates system troubleshooting supports. Code Development and Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical, and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. Tests the code using the appropriate testing approach. Deploys software to production servers. Contributes code documentation, maintains playbooks, and provides timely progress updates.\\n\\nMinimum education and experience required: Bachelor's degree or the equivalent in Computer Science, Information Technology, Engineering, or a related field plus 2 years of experience in software engineering or related experience; OR Master's degree or the equivalent in Computer Science, Information Technology, Engineering, or a related field.\\n\\nSkills required: Must have experience with: Programming language: Java and Scala/Python; Designing and developing REST API web services using Java and GraphQL; Framework used for distrusted computing: Apache Spark, Hadoop MapReduce, Google Dataflow; Clustering used to run distributing frameworks: Databricks, DataProc, Cloud Era, Hortonworks, Hadoop clusters; Real-time frameworks: Kafka, Structured Streaming, Kafka Connect, EventHub; CI/CD Deployment: Jenkin, Docker, Kubernetes, ARGO CD, Azure DevOps, GitHub, Airflow; File Format: Avro, Parquet, JSON, HUDI, DELTA, XML; Database: MySQL, Google Big Query, Presto, SQL Server, HDFS, HBase, Redis, Google storage, Azure Blob Storage; Alerting and monitoring: Grafana, Prometheus, Google monitoring; Logging: Splunk and Google Cloud logging; and Clouds and distribution: Google Cloud, Microsoft Azure working. Employer will accept any amount of experience with the required skills.\\n\\n#LI-DNP #LI-DNI\\n\\nWal-Mart is an Equal Opportunity Employer\",\n",
       "  'job_highlights': [{'items': [\"What you'll do...\\n\\nPosition: Data Engineer III\\n\\nJob Location: 805 SE Moberly Ln, Bentonville, AR 72712\\n\\nDuties: Problem Formulation: Identifies possible options to address the business problems within one's discipline through analytics, big data analytics, and automation. Applied Business Acumen: Supports the development of business cases and recommendations. Owns delivery of project activity and tasks assigned by others. Supports process updates and changes. Solves business issues. Data Governance: Supports the documentation of data governance processes. Supports the implementation of data governance practices. Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function. Data Transformation and Integration: Extracts data from identified databases. Creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques. Develops knowledge of... current data science and analytics trends. Data Source Identification: Supports the understanding of the priority order of requirements and service level agreements. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data. Data Modeling: Analyzes complex data elements, systems, data flows, dependencies, and relationships to contribute to conceptual, physical, and logical data models. Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs. Defines relational tables, primary and foreign keys, and stored procedures to create a data model structure. Evaluates existing data models and physical databases for variances and discrepancies. Develops efficient data flows. Analyzes data-related system integration challenges and proposes appropriate solutions. Creates training documentation and trains end-users on data modeling. Oversees the tasks of less experienced programmers and stipulates system troubleshooting supports. Code Development and Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical, and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. Tests the code using the appropriate testing approach. Deploys software to production servers. Contributes code documentation, maintains playbooks, and provides timely progress updates.\\n\\nMinimum education and experience required: Bachelor's degree or the equivalent in Computer Science, Information Technology, Engineering, or a related field plus 2 years of experience in software engineering or related experience; OR Master's degree or the equivalent in Computer Science, Information Technology, Engineering, or a related field.\\n\\nSkills required: Must have experience with: Programming language: Java and Scala/Python; Designing and developing REST API web services using Java and GraphQL; Framework used for distrusted computing: Apache Spark, Hadoop MapReduce, Google Dataflow; Clustering used to run distributing frameworks: Databricks, DataProc, Cloud Era, Hortonworks, Hadoop clusters; Real-time frameworks: Kafka, Structured Streaming, Kafka Connect, EventHub; CI/CD Deployment: Jenkin, Docker, Kubernetes, ARGO CD, Azure DevOps, GitHub, Airflow; File Format: Avro, Parquet, JSON, HUDI, DELTA, XML; Database: MySQL, Google Big Query, Presto, SQL Server, HDFS, HBase, Redis, Google storage, Azure Blob Storage; Alerting and monitoring: Grafana, Prometheus, Google monitoring; Logging: Splunk and Google Cloud logging; and Clouds and distribution: Google Cloud, Microsoft Azure working. Employer will accept any amount of experience with the required skills.\\n\\n#LI-DNP #LI-DNI\\n\\nWal-Mart is an Equal Opportunity Employer\"]}],\n",
       "  'related_links': [{'link': 'https://www.walmart.com/',\n",
       "    'text': 'walmart.com'},\n",
       "   {'link': 'https://www.google.com/search?sca_esv=05f85961c74d2d97&q=Walmart&sa=X&ved=0ahUKEwj2wbek__aEAxXhM0QIHR1gAbwQmJACCMwK',\n",
       "    'text': 'See web results for Walmart'}],\n",
       "  'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTM5FvH34ZOATLYnu5r4x6771B-yvvnvALrzttQHGCAW5FqQKRnaG-bXyo&s',\n",
       "  'extensions': ['2 days ago', 'Full-time'],\n",
       "  'detected_extensions': {'posted_at': '2 days ago',\n",
       "   'schedule_type': 'Full-time'},\n",
       "  'job_id': 'eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIElJSSIsImh0aWRvY2lkIjoiTFRTckp1N0VwSzI1dlB2TkFBQUFBQT09IiwiaGwiOiJlbiIsImZjIjoiRXFJQ0N1SUJRVTUxVjJoamEySjRlbVpSUVU4MlVsWkZVMjVsVUdaRVEweHhibkZaZG5wd01TMXpkRnBaVjNkcFVrWjZURmhKUTFsalNsZzVVbGRXTXpBeldsVjZhR0ZVY0dNMk1XcFRSbVF6U21abFFtSndhM1ZDYkVGTldIZ3RVazk2YWxsaVV6bFRSa1pVTkVWaGNXNVROVkkwZHpOMVpXcERZamhTZDJJM2VIVlBVeTF4VEZKSE5IQTFObUpYVURoa1NFNVZRakF3V0d4S09GZG1TbXRoY1ZsWmRubFRjR2hPZW1KQ1FrTldZMnRFWVVsSE5FVlNiREJhYldaNVFrZHZkVU5aVjFSUU0zQm9XSEJtV1dobWRFVjRUbkpOVjI1VGJsbzNkVmRqTkdOa1pHTjRRUklYV2paRU1GcGlZbmxEVDBodWExQkpVRzVqUTBZMFFYTWFJa0ZRV0dodE5XRTVOVlJGT0hSbVVtUm5VMHhSWDNwVFIyaGZVbUY1UTNZeFZFRSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzUiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gQ2FyZWVycy5XYWxtYXJ0LmNvbSIsImxpbmsiOiJodHRwczovL2NhcmVlcnMud2FsbWFydC5jb20vdXMvam9icy9XRDE4MTIzMzItZGF0YS1lbmdpbmVlci1paWk/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=='},\n",
       " {'title': 'Data Analytics Engineer (Power BI Developer)',\n",
       "  'company_name': 'Thoughtwave Software and Solutions',\n",
       "  'location': '  United States   ',\n",
       "  'via': 'via Dice',\n",
       "  'description': \"Role- Data Analytics Engineer (Power BI Developer)\\nLocation:Hybrid role- 3 days on site (Tues-Thurs) in either Chicago, IL or Columbia, MD\\nDuration:FullTime...\\n\\nMust Haves:\\nPower BI and DAX experience\\n\\nResponsibilities\\nTranslate business needs into technical specification.\\nDevelop, design and maintain efficient enterprise-grade Power BI dashboards, reports and datasets adhering to industry best practices.\\nReview, interpret, troubleshoot and optimize SQL queries. Develop maintainable code via proper structures, comments, and design using best practices.\\nThoroughly validate the reports data being presented to build trust in the BI solutions provided to end users.\\nProvide feedback as needed to internal and external resources that provide source data.\\nDemonstrate proficiency in the use of business intelligence technologies.\\nPerform source data analysis data profiling, validation, conceptual and logical data modeling, etc.\\nto determine the suitability of the source data for meeting the reporting requirements.\\nMeet with subject matter experts in different areas of the business, be able to learn the concepts\\nand business language relevant to their line of business and develop an understanding of how their data supports their business processes.\\nCollaborate with partners to develop business requirements leading to successful project outcomes. Inform and drive innovative approaches for assigned solutions.\\nAdheres to project methodology, change management, and departmental procedures.\\nGood ability to interact in a team environment with peers and members of other teams that might even be located remotely.\\n\\nQualifications\\nBachelor's Degree in Computer Science, Engineering or Information Systems. Required\\n2 years Proficient BI developer with developing BI reports and Dashboards in Power BI Required.\\nKnowledge in performing data manipulation using Dataflows, Power Query and DAX calculations using Power BI.\\n2 years SQL experience with Relational Database Management Systems (RDBMS) Required\\nExperience with the Agile Methodology Preferred.\\nExperience in data modeling and entity relationship diagram conventions and various data modeling patterns Preferred.\\nExperience using cloud technologies such as Google Cloud Platform (Google Cloud Platform)\\nUnderstanding and application of BI technologies, including security, portal settings, data connection settings, refresh frequencies,\\ninteraction with data sources, etc.\\nStrong visualization skills with proven ability to utilize the full functionality of Power BI or similar BI tools.\\nExcellent listening, verbal and written communication skills; ability to communicate effectively at all levels of the organization.\\nStrong collaboration and interpersonal skills.\\nDemonstrated ability to perform duties and responsibilities on time with moderate supervision.\\n\\nBhargavi Ankam\\nIT Recruiter\\nStaffing | Thoughtwave Software and Solutions Limited\\n\\n314 N. Lake St, Suite 6, Aurora IL 60506\\nA Certified Minority Business Enterprise, Disadvantaged Business Enterprise, SAM.gov, SOC2 & ISO2005,\\nVendors for:\\nSTATES: IL, PA, TN, AK, OR, CT, GA, VA, ID, IA, UT, FL, MN & CO,\\nNATIONAL LABS: ARGONNE & FERMI,\\nCOUNTIES: HENNEPIN, MN, FULTON & GA,\\nPUBLIC SCHOOLS: ATLANTA\",\n",
       "  'job_highlights': [{'title': 'Qualifications',\n",
       "    'items': ['Good ability to interact in a team environment with peers and members of other teams that might even be located remotely',\n",
       "     \"Bachelor's Degree in Computer Science, Engineering or Information Systems\",\n",
       "     '2 years Proficient BI developer with developing BI reports and Dashboards in Power BI Required',\n",
       "     'Knowledge in performing data manipulation using Dataflows, Power Query and DAX calculations using Power BI',\n",
       "     '2 years SQL experience with Relational Database Management Systems (RDBMS) Required',\n",
       "     'Experience using cloud technologies such as Google Cloud Platform (Google Cloud Platform)',\n",
       "     'Understanding and application of BI technologies, including security, portal settings, data connection settings, refresh frequencies,',\n",
       "     'Strong visualization skills with proven ability to utilize the full functionality of Power BI or similar BI tools',\n",
       "     'Excellent listening, verbal and written communication skills; ability to communicate effectively at all levels of the organization',\n",
       "     'Strong collaboration and interpersonal skills',\n",
       "     'Demonstrated ability to perform duties and responsibilities on time with moderate supervision']},\n",
       "   {'title': 'Responsibilities',\n",
       "    'items': ['Translate business needs into technical specification',\n",
       "     'Develop, design and maintain efficient enterprise-grade Power BI dashboards, reports and datasets adhering to industry best practices',\n",
       "     'Review, interpret, troubleshoot and optimize SQL queries',\n",
       "     'Develop maintainable code via proper structures, comments, and design using best practices',\n",
       "     'Thoroughly validate the reports data being presented to build trust in the BI solutions provided to end users',\n",
       "     'Provide feedback as needed to internal and external resources that provide source data',\n",
       "     'Demonstrate proficiency in the use of business intelligence technologies',\n",
       "     'Perform source data analysis data profiling, validation, conceptual and logical data modeling, etc',\n",
       "     'to determine the suitability of the source data for meeting the reporting requirements',\n",
       "     'Meet with subject matter experts in different areas of the business, be able to learn the concepts',\n",
       "     'and business language relevant to their line of business and develop an understanding of how their data supports their business processes',\n",
       "     'Collaborate with partners to develop business requirements leading to successful project outcomes',\n",
       "     'Inform and drive innovative approaches for assigned solutions',\n",
       "     'Adheres to project methodology, change management, and departmental procedures']}],\n",
       "  'related_links': [{'link': 'https://www.google.com/search?sca_esv=05f85961c74d2d97&q=Thoughtwave+Software+and+Solutions&sa=X&ved=0ahUKEwj2wbek__aEAxXhM0QIHR1gAbwQmJACCJgL',\n",
       "    'text': 'See web results for Thoughtwave Software and Solutions'}],\n",
       "  'extensions': ['1 day ago', 'Full-time'],\n",
       "  'detected_extensions': {'posted_at': '1 day ago',\n",
       "   'schedule_type': 'Full-time'},\n",
       "  'job_id': 'eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5dGljcyBFbmdpbmVlciAoUG93ZXIgQkkgRGV2ZWxvcGVyKSIsImh0aWRvY2lkIjoiR1ZFMkYwY0NwTGpXYlBmTkFBQUFBQT09IiwiaGwiOiJlbiIsImZjIjoiRXN3Q0Nvd0NRVTUxVjJoamJYRmtTalZrV21NM1drRnlaMnM0YXpaRlEzSktXVXhWVWtWdWJFMU1NSHBXWlhSNE1ucGlTM1JzYjI5VVMxOUtaa1JNWlVsUlRsOXJRbUV6ZVdObldHNHhYMFZTTXkwMlZWTXROekYwWW5acE16bEZWR2x2ZFZaNE9TMVFNa3RyTVVwMVJtaDNZVGRSVGtkdWRuWm5WbFpwUTBWT1VEVm1hRFpLTVhKU1oxQkRWazlJZGxwVVkyOUtaelV0TUVkVmEwaDZkbVJKY1RoQ2NVaGpSMGxNTlhOMmNYWnRPRmhXTW5GWWNVdGtTMmhGYjNwc1VGSlhTbUoxTjFSTVIxTlpWMDlSUVZSQ01VWk1hekpZWVdabGRucHNPV0l3YkU5d2VIRnZRakV0ZFdWWFFqbFJSM0ZOTmxkdlNVZHFaVmh0TFRZemRrVndZamczUW1aUlpIUlphM0JEUVhsMlRSSVhXalpFTUZwaVlubERUMGh1YTFCSlVHNWpRMFkwUVhNYUlrRlFXR2h0TldJM1EyUkdOREJWYUdwTWVVZGZTVEJJY21zMmMyUkJZM1pMTm1jIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfNyIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBEaWNlIiwibGluayI6Imh0dHBzOi8vd3d3LmRpY2UuY29tL2pvYi1kZXRhaWwvNDM3NjAxZjMtMzFkMy00NWExLThjNzctMzRmNTE1MGMxZDczP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0='},\n",
       " {'title': 'Client Performance Analytics-Senior Engineer (Data Design)',\n",
       "  'company_name': 'American Express',\n",
       "  'location': '  Kansas   ',\n",
       "  'via': 'via Eightfold - Eightfold.ai',\n",
       "  'description': \"Accertify is the trusted partner to the world’s leading eCommerce brands. We help our clients grow revenue and protect against loss with industry-leading fraud prevention and digital identity offerings. When you join Accertify, you become part of the digital solution to enable legitimate eCommerce, delivering peace of mind to merchants and their customers across the globe. #TeamAccertify provides... a solution merchants trust and a career you can trust.\\n\\nAccertify is a wholly owned subsidiary of American Express--which means our team has access to the amazing perks and benefits offered by our parent company. We are proud to be #TeamAccertify and #TeamAmex.\\n\\nAccertify is growing, and we are looking to add a Client Performance Analytics -Senior Engineer (Data Design) to our global fraud-fighting team.\\n\\nHow will you make an impact in this role?\\n\\nThis Client Performance Analytics role is positioned within Accertify’s Product Development organization and is responsible for developing data sources and compilation processes in support of reporting and analytics features. This individual will work in a cross-functional capacity alongside members of Accertify technical and business teams, which include product management, development, big data, decision sciences, architecture, and client-facing teams.\\n\\nResponsibilities:\\n• Design, code, and document data compilation and aggregate processes to make large-scale data sources available to user-facing BI features\\n• Contribute to validation and monitoring processes to ensure the integrity of data compilations and code\\n• Partner with Client Performance Analytics and Product Management colleagues to design efficient and resilient data sources that meet business needs\\n• Partner with Data Design and Big Data colleagues to optimize compilation processes and data availability across multiple data centers\\n• Partner with Product Development to incorporate data sources into user-facing product features\\n• With Data Governance and client-facing business teams, create processes to identify and address data definition and mapping issues\\n• Apply Development best practices to code review and change management processes\\n• Other ad-hoc data sourcing or analytic responsibilities as assigned\\n\\nQualifications:\\n• Minimum four years of applied coding experience in software development or Big Data architecture\\n• Fluency in one or more of the following coding languages and platforms: Python, Scala, Java, Spark, PySpark, SQL, Flink, Drill\\n• Experience with version control procedures and software (Gitlab)\\n• Familiarity with data compilation concepts and best practices; experience building efficient aggregation processes and highly performant data sources\\n• Applied experience in process optimization and troubleshooting complex data relationships\\n• Proven ability to effectively communicate with internal departments and stakeholders to deliver highly detailed technical information\\n• Ability to maintain resiliency and handle ambiguity in a fast-paced, heavily customized environment with high-profile, strategic enterprise clients\\n• Must be collaborative, motivated, creative, and results-oriented\\n\\nPreferred Qualifications:\\n• Bachelor’s degree or higher in Computer Science, Engineering, Data Science, Data Analytics, or related field\\n• Certifications in the languages or platforms listed above or in related areas\\n• Experience integrating Big Data and aggregate sources into user-facing BI objects; preferred experience with Tableau or similar software\\n• Experience in the Fraud or Risk Detection industry\\n• Knowledge of and experience with online payment processors, billing service providers, and tools/platforms/resources used to combat online fraud\\n• Experience with Accertify Interceptas and Account Protection products and technical infrastructure\\n\\nSalary Range: $70,000.00 to $135,000.00 annually + bonus + benefits\\n\\nEmployment eligibility to work with American Express in the U.S. is required as the company will not pursue visa sponsorship for these positions.\\n\\nThe above represents the expected salary range for this job requisition. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.\\n\\nWe back our colleagues and their loved ones with benefits and programs that support their holistic well-being. That means we prioritize their physical, financial, and mental health through each stage of life. Benefits include:\\n• Competitive base salaries\\n• Bonus incentives\\n• 6% Company Match on retirement savings plan\\n• Free financial coaching and financial well-being support\\n• Comprehensive medical, dental, vision, life insurance, and disability benefits\\n• Flexible working model with hybrid, onsite or virtual arrangements depending on role and business need\\n• 20+ weeks paid parental leave for all parents, regardless of gender, offered for pregnancy, adoption or surrogacy\\n• Free access to global on-site wellness centers staffed with nurses and doctors (depending on location)\\n• Free and confidential counseling support through our Healthy Minds program\\n• Career development and training opportunities\\n\\nFor a full list of Team Amex benefits, visit our Colleague Benefits Site.\\n\\nAmerican Express is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other status protected by law.\\n\\nWe back our colleagues with the support they need to thrive, professionally and personally. That's why we have Amex Flex, our enterprise working model that provides greater flexibility to colleagues while ensuring we preserve the important aspects of our unique in-person culture. Depending on role and business needs, colleagues will either work onsite, in a hybrid model (combination of in-office and virtual days) or fully virtually.\\n\\nUS Job Seekers/Employees - Click here to view the “Know Your Rights” poster and the Pay Transparency Policy Statement.\\n\\nIf the links do not work, please copy and paste the following URLs in a new browser window: https://www.dol.gov/agencies/ofccp/posters to access the three posters\",\n",
       "  'job_highlights': [{'title': 'Qualifications',\n",
       "    'items': ['Minimum four years of applied coding experience in software development or Big Data architecture',\n",
       "     'Fluency in one or more of the following coding languages and platforms: Python, Scala, Java, Spark, PySpark, SQL, Flink, Drill',\n",
       "     'Experience with version control procedures and software (Gitlab)',\n",
       "     'Familiarity with data compilation concepts and best practices; experience building efficient aggregation processes and highly performant data sources',\n",
       "     'Applied experience in process optimization and troubleshooting complex data relationships',\n",
       "     'Proven ability to effectively communicate with internal departments and stakeholders to deliver highly detailed technical information',\n",
       "     'Ability to maintain resiliency and handle ambiguity in a fast-paced, heavily customized environment with high-profile, strategic enterprise clients',\n",
       "     'Must be collaborative, motivated, creative, and results-oriented']},\n",
       "   {'title': 'Responsibilities',\n",
       "    'items': ['This Client Performance Analytics role is positioned within Accertify’s Product Development organization and is responsible for developing data sources and compilation processes in support of reporting and analytics features',\n",
       "     'This individual will work in a cross-functional capacity alongside members of Accertify technical and business teams, which include product management, development, big data, decision sciences, architecture, and client-facing teams',\n",
       "     'Design, code, and document data compilation and aggregate processes to make large-scale data sources available to user-facing BI features',\n",
       "     'Contribute to validation and monitoring processes to ensure the integrity of data compilations and code',\n",
       "     'Partner with Client Performance Analytics and Product Management colleagues to design efficient and resilient data sources that meet business needs',\n",
       "     'Partner with Data Design and Big Data colleagues to optimize compilation processes and data availability across multiple data centers',\n",
       "     'Partner with Product Development to incorporate data sources into user-facing product features',\n",
       "     'With Data Governance and client-facing business teams, create processes to identify and address data definition and mapping issues',\n",
       "     'Apply Development best practices to code review and change management processes',\n",
       "     'Other ad-hoc data sourcing or analytic responsibilities as assigned']},\n",
       "   {'title': 'Benefits',\n",
       "    'items': ['Salary Range: $70,000.00 to $135,000.00 annually + bonus + benefits',\n",
       "     \"Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors\",\n",
       "     'We back our colleagues and their loved ones with benefits and programs that support their holistic well-being',\n",
       "     'Competitive base salaries',\n",
       "     'Bonus incentives',\n",
       "     '6% Company Match on retirement savings plan',\n",
       "     'Free financial coaching and financial well-being support',\n",
       "     'Comprehensive medical, dental, vision, life insurance, and disability benefits',\n",
       "     'Flexible working model with hybrid, onsite or virtual arrangements depending on role and business need',\n",
       "     '20+ weeks paid parental leave for all parents, regardless of gender, offered for pregnancy, adoption or surrogacy',\n",
       "     'Free access to global on-site wellness centers staffed with nurses and doctors (depending on location)',\n",
       "     'Free and confidential counseling support through our Healthy Minds program',\n",
       "     'Career development and training opportunities']}],\n",
       "  'related_links': [{'link': 'http://www.americanexpress.com/',\n",
       "    'text': 'americanexpress.com'},\n",
       "   {'link': 'https://www.google.com/search?sca_esv=05f85961c74d2d97&q=American+Express&sa=X&ved=0ahUKEwj2wbek__aEAxXhM0QIHR1gAbwQmJACCOYL',\n",
       "    'text': 'See web results for American Express'}],\n",
       "  'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTLdgalLcstr48gAzbyJ0nOlmdDWjnXhMyz1iRY&s=0',\n",
       "  'extensions': ['23 hours ago',\n",
       "   'Full-time',\n",
       "   'Health insurance',\n",
       "   'Dental insurance'],\n",
       "  'detected_extensions': {'posted_at': '23 hours ago',\n",
       "   'schedule_type': 'Full-time'},\n",
       "  'job_id': 'eyJqb2JfdGl0bGUiOiJDbGllbnQgUGVyZm9ybWFuY2UgQW5hbHl0aWNzLVNlbmlvciBFbmdpbmVlciAoRGF0YSBEZXNpZ24pIiwiaHRpZG9jaWQiOiJhN1lNcEZkSXYtRm9BdlAyQUFBQUFBPT0iLCJobCI6ImVuIiwiZmMiOiJFdUlDQ3FJQ1FVNTFWMmhqYkdoV2RIQTRNRmRuYjFWRU1rZHdkSFpTUm5samR6Y3llSEUxYjJ4R01WVmlaVk5CVGpFd1RWRlJOakJsYldoTU9UWktSSEJNYVdGVE5FZERhalprYTBNeVlUUk1UREY2VGpkemNtZENTbk5ZV1dWUlVFUnpablpqVG05ck1IYzNXakZTZDFCWFkwWjVRVkkwZEVORFQwVjJOV3d0VkVvNWVEbFVRekUxTkdOWGRVUjFiMU4xVEZsdWFtaENYMkZ4UVRGUk1qbFlkMWxuWTFscmNEZzBiMjVmWVVwdWREVkhNR2xDYnpaa1JHMW1RbTlRUTB4TU9WRk5UMmN5U2tOalh6VTNTblZYUldwSlRURlpUR05NZGpReFMwRlpNbEV3UjBJMlVVWXhSbDgxYlZkSGVVZGtkRVpUYTFkbGFsUlpWMDlHUjNCeFZVZzBXVlZmVkVGVU4xTlZjVTVNWHpFemVWcHpTbU5SYTFSS1QwRXdYek51Y2s5aWFVRVNGMW8yUkRCYVltSjVRMDlJYm10UVNWQnVZME5HTkVGekdpSkJVRmhvYlRWaFFWbDZWbVl5WmpjMll6UnBOMTlFVFRaWVNUTldlVFUwY1RGUiIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzgiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gRWlnaHRmb2xkIC0gRWlnaHRmb2xkLmFpIiwibGluayI6Imh0dHBzOi8vYWV4cC5laWdodGZvbGQuYWkvY2FyZWVycy9qb2IvMjEwOTQyNzYtY2xpZW50LXBlcmZvcm1hbmNlLWFuYWx5dGljcy1zZW5pb3ItZW5naW5lZXItZGF0YS1kZXNpZ24tLXVuaXRlZC1zdGF0ZXM/ZG9tYWluPWFleHAuY29tXHUwMDI2dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=='},\n",
       " {'title': 'Data Engineer',\n",
       "  'company_name': 'Cognizant Technology Solutions',\n",
       "  'location': '  United States   ',\n",
       "  'via': 'via Cognizant',\n",
       "  'description': \"Data Engineer\\n\\nPosition Overview...\\n\\nA Data Engineer in Cognizant’s AIA (AI & Analytics) practice brings relevant context to data for business and IT for intelligent systems and critical decisions. They work within the domains of data management, to integrate high-variation and/or high-velocity data to produce answers and enable clients to ask an entirely new class of questions. They will use a variety of tools and techniques to deliver better, faster, and intelligent data to some of the world’s most successful businesses – our clients.\\n\\nResponsibilities\\n• Build and deliver data pipelines to store data in a way that is accessible, performant, secure, and sustainable\\n• Prototype solutions, prepare test scripts, and conduct tests for data replication, extraction, loading, cleansing, and data modeling for data warehouses\\n• Review and validate data loaded into data lakes/warehouses for accuracy\\n• Develop proofs of concept and evaluate design options to deliver ingestion, search, metadata cataloging and scheduling of data pipelines\\n• Data engineering in line with standard processes and Cognizant’s reference architecture\\n• Understand and detail technical use case requirements to deliver data movement and transformation solutions\\n\\nBasic Qualifications\\n• Bachelor's degree in IT-related field and 0-3 years of IT experience\\n• Strong business interpersonal skills (including written and oral)\\n• Programming experience with Python, Python Pyspark or Java development for modern data engineering\\n• Strong background in relational data models\\n• Exposure in Data Pipelines & SQL / NoSQL (e.g. Cassandra, HBase) and Relational Database management systems\\n• Exposure to implementing PaaS services on public clouds - Azure, AWS, GCP, Databricks, Snowflake, SingleStore, Oracle, Informatica\\n• Strong problem solving and analytical thinking skills\\n\\nDistinguishing Qualifications\\n• Full Data lifecycle development experience\\n• Industry experience (financial services, insurance, retail, healthcare, life sciences, communications)\\n• Experience in developing and deploying distributed computing applications using Open Source or cloud native services.\\n• Shown understanding of data applications including Hadoop components (HDFS, HBase, Hive, Sqoop, Flume, etc.)\\n• Exposure to data analytics and data mining tools/applications such as Tableau, QlikSense /QlikView, R or SAS\\n• Exposure to working with SQL, Relational Database Management Systems (e.g., SQL Server, Oracle)\\n• Development workflows (e.g., Microsoft VSTS)\\n• Experience leading teams\\n\\nLocation\\n\\nData Engineers will be deployed to these cities: Austin, TX; Dallas, TX; Bentonville, AR; Charlotte, NC; Cincinnati, OH; Columbus, OH; Hartford, CT; Juno Beach, FL; Mountain View, CA; Basking Ridge, NJ; Mt Laurel, NJ; New York, NY; Oakland, CA; Owing Mills, MD; Pleasanton, TX; Portland, OR; Richmond, VA; St. Louis, MO; Santa Clara, CA; Seattle, WA where you will work alongside other experienced Cognizant associates delivering technology solutions. Applicants must be willing to relocate to one of these major geographic areas.\\n\\nStart Date\\n\\nData Engineers will start in two cohorts: June or August 2024. We will communicate your exact start date at the time of offer. While we will attempt to honor candidate start date preferences, business need and position availability will determine final start date. Exact start dates will be communicated with enough time for you to plan effectively.\\n\\nWhy Choose Us?\\n\\nCognizant delivers solutions that draw upon the full power and scale of our associates. You will be supported by high-caliber experts and employ some of the most sophisticated and patented capabilities. Our associate’s diverse set of backgrounds offer varied perspectives and fuel new ways of thinking. We encourage lively discussions which inspire better results for our clients.\\n\\nIf you’re comfortable with ambiguity, excited by change, and excel through autonomy, we’d love to hear from you!\\n\\nSalary and Other Compensation:\\n\\nThe annual salary for this role is $73,000.00 depending on experience and other qualifications of the successful candidate.\\n\\nThis position is also eligible for Cognizant’s discretionary annual incentive program, based on performance and subject to the terms of Cognizant’s applicable plans.\\n\\nBenefits:\\n\\nCognizant offers the following benefits for this position, subject to applicable eligibility requirements:\\n• Medical/Dental/Vision/Life Insurance\\n• Paid holidays plus Paid Time Off\\n• 401(k) plan and contributions\\n• Long-term/Short-term Disability\\n• Paid Parental Leave\\n• Employee Stock Purchase Plan\\n\\nDisclaimer:\\n\\nThe salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law.\\n\\nWork Authorization\\n\\nDue to the nature of this position, Cognizant cannot provide sponsorship for U.S. work authorization (including participation in a CPT/OPT program\",\n",
       "  'job_highlights': [{'title': 'Qualifications',\n",
       "    'items': [\"Bachelor's degree in IT-related field and 0-3 years of IT experience\",\n",
       "     'Strong business interpersonal skills (including written and oral)',\n",
       "     'Programming experience with Python, Python Pyspark or Java development for modern data engineering',\n",
       "     'Strong background in relational data models',\n",
       "     'Exposure in Data Pipelines & SQL / NoSQL (e.g. Cassandra, HBase) and Relational Database management systems',\n",
       "     'Exposure to implementing PaaS services on public clouds - Azure, AWS, GCP, Databricks, Snowflake, SingleStore, Oracle, Informatica',\n",
       "     'Strong problem solving and analytical thinking skills',\n",
       "     'Full Data lifecycle development experience',\n",
       "     'Industry experience (financial services, insurance, retail, healthcare, life sciences, communications)',\n",
       "     'Experience in developing and deploying distributed computing applications using Open Source or cloud native services',\n",
       "     'Shown understanding of data applications including Hadoop components (HDFS, HBase, Hive, Sqoop, Flume, etc.)',\n",
       "     'Exposure to data analytics and data mining tools/applications such as Tableau, QlikSense /QlikView, R or SAS',\n",
       "     'Exposure to working with SQL, Relational Database Management Systems (e.g., SQL Server, Oracle)',\n",
       "     'Development workflows (e.g., Microsoft VSTS)',\n",
       "     'Experience leading teams']},\n",
       "   {'title': 'Responsibilities',\n",
       "    'items': ['They work within the domains of data management, to integrate high-variation and/or high-velocity data to produce answers and enable clients to ask an entirely new class of questions',\n",
       "     'They will use a variety of tools and techniques to deliver better, faster, and intelligent data to some of the world’s most successful businesses – our clients',\n",
       "     'Build and deliver data pipelines to store data in a way that is accessible, performant, secure, and sustainable',\n",
       "     'Prototype solutions, prepare test scripts, and conduct tests for data replication, extraction, loading, cleansing, and data modeling for data warehouses',\n",
       "     'Review and validate data loaded into data lakes/warehouses for accuracy',\n",
       "     'Develop proofs of concept and evaluate design options to deliver ingestion, search, metadata cataloging and scheduling of data pipelines',\n",
       "     'Data engineering in line with standard processes and Cognizant’s reference architecture',\n",
       "     'Understand and detail technical use case requirements to deliver data movement and transformation solutions']},\n",
       "   {'title': 'Benefits',\n",
       "    'items': ['The annual salary for this role is $73,000.00 depending on experience and other qualifications of the successful candidate',\n",
       "     'This position is also eligible for Cognizant’s discretionary annual incentive program, based on performance and subject to the terms of Cognizant’s applicable plans',\n",
       "     'Medical/Dental/Vision/Life Insurance',\n",
       "     'Paid holidays plus Paid Time Off',\n",
       "     '401(k) plan and contributions',\n",
       "     'Long-term/Short-term Disability',\n",
       "     'Paid Parental Leave',\n",
       "     'Employee Stock Purchase Plan']}],\n",
       "  'related_links': [{'link': 'http://www.cognizant.com/',\n",
       "    'text': 'cognizant.com'},\n",
       "   {'link': 'https://www.google.com/search?sca_esv=05f85961c74d2d97&q=Cognizant+Technology+Solutions&sa=X&ved=0ahUKEwj2wbek__aEAxXhM0QIHR1gAbwQmJACCLcM',\n",
       "    'text': 'See web results for Cognizant Technology Solutions'}],\n",
       "  'extensions': ['5 days ago',\n",
       "   'Full-time',\n",
       "   'Health insurance',\n",
       "   'Dental insurance',\n",
       "   'Paid time off'],\n",
       "  'detected_extensions': {'posted_at': '5 days ago',\n",
       "   'schedule_type': 'Full-time'},\n",
       "  'job_id': 'eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiJSZ2RJZ1k5RS1ISURQb3RkQUFBQUFBPT0iLCJobCI6ImVuIiwiZmMiOiJFcUlDQ3VJQlFVNTFWMmhqYlVsYWIyVTRkekJEWDJGSlZVODFkR3d6ZEZWNFUwZ3pkWFpZVUcxRWFUUkJSV3RUU1hacVJFMUhhMnAzUTNnemMzVjZZbDh5VnpORVluTnNiamhFYTJzMVkyUlVWM0ZIWkVSVFZqZFhNamxsTUVGU01HeFVkMDlpYTJST01HUk9WSEpWTmsxdFpsWkhSMUJJZUdSYWRGbHFTMGcyYVZaTkxXeFRZVzlwZUhCUldXeHBVVVJLTFRkNE4wcEdkbEpPTFZrMVNWZDBiREZoVm1aUFdrRlRlbEF3VEZSc00xSTJNWGhvUjA4MGRUZFdOVXBtVEZSdmFHUTJXWE5GV1ZWc2QydDVUVzV6TkVGd2NYSnlWME5sVHpKTWRtTlhTVVZ2Um5KTVVSSVhXalpFTUZwaVlubERUMGh1YTFCSlVHNWpRMFkwUVhNYUlrRlFXR2h0TldGRVdpMXRZMjlsWlV4TVYzWnNRWGxrVGpoMGJtNVZhekJsTFVFIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTAiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gQ29nbml6YW50IiwibGluayI6Imh0dHBzOi8vY2FyZWVycy5jb2duaXphbnQuY29tL2dsb2JhbC9lbi9qb2IvNDM5NDEvRGF0YS1FbmdpbmVlcj91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19'},\n",
       " {'title': 'Data Engineer - Corporate (Las Vegas)',\n",
       "  'company_name': 'Caesars Entertainment',\n",
       "  'location': '  United States   ',\n",
       "  'via': 'via Dice',\n",
       "  'description': \"JOB DESCRIPTION\\n\\nESSENTIAL JOB FUNCTIONS...\\n\\nThe Data Engineer is a data and technology expert supporting the broader Data Engineering team. The primary responsibility of a Data Engineer is to develop, maintain, and support data ingestion pipelines. Candidates that succeed in this role have a passion for technology and innovation, and understand the business value and meaning behind the data they work with. An ideal candidate should have a proven history as a strong independent contributor that designs source to target pipelines in a cloud first environment.\\n\\nResponsibilities include, but may not be limited to the following:\\n• Collaborate with business users to gather requirements, write functional and technical specifications and communicate technical requirements.\\n• Develop, configure, and support complex SQL and/or ETL solutions within various computing environments and pipelines.\\n• Define new capabilities and identify opportunities for continuous improvement.\\n• Document and comment code from design to completion to assist in future understanding of solutions.\\n• Perform technical reviews of code to maintain consistent technical direction and minimize system impact on production pipeline.\\n• Ability to work with stakeholders to identify high priority items and to allocate time effectively to meet expected deadlines.\\n• Provide support for production data pipelines and associated technology.\\n\\nTECHNICAL SKILLS REQUIRED\\n• Expertise in SQL is required; Must be comfortable working with large structured and unstructured datasets, and writing complex SQL logic to achieve the desired output.\\n• Background in end-to-end data pipeline development and deployment with at least 1+ year hands-on experience with cloud platforms required. Familiarity with SQL orchestration tools like Airflow and cloud platforms like Snowflake, Google Cloud Platform, or Azure highly preferred.\\n• Hands on development experience using ETL tools and code repositories required.\\n• Experience with programming languages such as C# and Python.\\n• Experience with modern BI Reporting platforms (such as Tableau, Power BI) preferred.\\n\\nKNOWLEDGE AND EXPERIENCE\\n• Minimum of 3 years of full-time work experience in data field\\n• Bachelor s degree in technical field highly preferred\\n• Candidates must have the ability to uphold and demonstrate the highest level of integrity in all situations and recognize standards required by a regulated business.\\n\\nABOUT US\\n\\nAt Caesars Entertainment, Inc., our Team Members create the extraordinary. We are the largest casino-entertainment company in the U.S. and one of the world's most diversified casino-entertainment providers. Since beginning in Reno, Nevada, in 1937, Caesars Entertainment has grown through the development of new resorts, expansions and acquisitions. Our resorts operate primarily under the Caesars , Harrah's , Horseshoe and Eldorado brand names. We focus on building loyalty and value with our guests through a combination of impeccable service, operational excellence and technological leadership. The company is committed to its Team Members, suppliers, communities and the environment through its PEOPLE PLANET PLAY framework.\\n\\nOur Caesars family is driven by our Mission, Vision and Values. We take great pride in living these values - Together We Win, All In On Service and Blaze the Trail - every day. Our mission, Create the Extraordinary . Our vision, Create spectacular worlds. That immerse, inspire and connect you. We don t perform magic; we create it with excellence. #WeAreCaesars . If you are ready to create some magic, we invite you to explore our dynamic, yet unique, career opportunities\",\n",
       "  'job_highlights': [{'title': 'Qualifications',\n",
       "    'items': ['Background in end-to-end data pipeline development and deployment with at least 1+ year hands-on experience with cloud platforms required',\n",
       "     'Minimum of 3 years of full-time work experience in data field',\n",
       "     'Candidates must have the ability to uphold and demonstrate the highest level of integrity in all situations and recognize standards required by a regulated business']},\n",
       "   {'title': 'Responsibilities',\n",
       "    'items': ['The Data Engineer is a data and technology expert supporting the broader Data Engineering team',\n",
       "     'The primary responsibility of a Data Engineer is to develop, maintain, and support data ingestion pipelines',\n",
       "     'Collaborate with business users to gather requirements, write functional and technical specifications and communicate technical requirements',\n",
       "     'Develop, configure, and support complex SQL and/or ETL solutions within various computing environments and pipelines',\n",
       "     'Define new capabilities and identify opportunities for continuous improvement',\n",
       "     'Document and comment code from design to completion to assist in future understanding of solutions',\n",
       "     'Perform technical reviews of code to maintain consistent technical direction and minimize system impact on production pipeline',\n",
       "     'Ability to work with stakeholders to identify high priority items and to allocate time effectively to meet expected deadlines',\n",
       "     'Provide support for production data pipelines and associated technology']}],\n",
       "  'related_links': [{'link': 'https://www.google.com/search?sca_esv=05f85961c74d2d97&q=Caesars+Entertainment&sa=X&ved=0ahUKEwj2wbek__aEAxXhM0QIHR1gAbwQmJACCIMN',\n",
       "    'text': 'See web results for Caesars Entertainment'}],\n",
       "  'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcShmgCU4uK4fcEwPxfhL9zFIhpHeqfjqSA13Z00u7n3h5VbpARS61MiNAY&s',\n",
       "  'extensions': ['19 hours ago', 'Full-time'],\n",
       "  'detected_extensions': {'posted_at': '19 hours ago',\n",
       "   'schedule_type': 'Full-time'},\n",
       "  'job_id': 'eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIC0gQ29ycG9yYXRlIChMYXMgVmVnYXMpIiwiaHRpZG9jaWQiOiJtb3pWUnQ0T0w3RWZZQi1BQUFBQUFBPT0iLCJobCI6ImVuIiwiZmMiOiJFcmNDQ3ZjQlFVNTFWMmhqYmtVdFpGSjJOazl4UlRNemFVRmxhbUY2ZWs5UFh6UlljWGQwZFRGUVdXVmhlakIyU0RoM2VqTlNVMmR6ZFhKUVYycHlkR054YmpNMVdrRkdaWGxPYTBZdFUyOXdWWGRxVjNGaU1GSmhTVTVYVFZaWFkxUXhVMmhHU3pGNGVrNUZlbnBhUTBWME1VUXlPRVpWVldkc1MxTm9jVFU0WTNsTWQweGtWMFJYTVhwck9VNVBiSFp1U1ZVMVlrVkJSV05zU1dsak5rc3RZelZ0TlhkR1kyeHFZWEJ5VjE5dUxWSnVTMVF0ZERJelkwVk9WREJhTjA1UE1YRXhOa2hETTNCeGNXZEhZazFSTFZaaVVGRnRlR1ozTldST1NuZERWbko0TjBGdllXaEtaRTk2UkZoaGRqSldPSEl0UjJ0dmRraGxieElYV2paRU1GcGlZbmxEVDBodWExQkpVRzVqUTBZMFFYTWFJa0ZRV0dodE5XRjJMVVJuZEZOdldVVmFNbkJVU0dOUE0wMWZjRWg1WHpZNVprRSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEyIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIERpY2UiLCJsaW5rIjoiaHR0cHM6Ly93d3cuZGljZS5jb20vam9iLWRldGFpbC8zNjU5MzU4Zi0xZTgyLTQ0NmItYjAyMi02MjYyZWUxMzRlMjY/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=='},\n",
       " {'title': 'Jr Data Analytics Engineer',\n",
       "  'company_name': 'Echelon Services, LLC',\n",
       "  'location': ' Anywhere ',\n",
       "  'via': 'via LinkedIn',\n",
       "  'description': 'Echelon Services seeks a highly motivated and skilled Jr Data Analytics Engineer. The ideal candidate will be responsible for providing strategic guidance on data analytics and implementation practices in a government setting.\\n\\nWork Location...\\n• This role requires occasional onsite work. The candidate will need to travel to Richmond, Va, on occasion for on-site work.\\n\\nEssential Functions\\n• Develops the data extraction and preparation processes.\\n• Runs data quality audits and identifies issues with data collection.\\n• Implements improvements and fixes to data collection processes.\\n• Oversees SQL databases that can be large and complex.\\n\\nQualifications\\n• 4 years of relevant experience with a bachelor’s degree in computer science, engineering, mathematics, or other related discipline. (Or a master’s degree and 1 year, a Ph.D. and 0 years)\\n• Preference for IAT Level II certification\\n• An active secret clearance or higher is REQUIRED\\n\\nSalary - $110,000 - $114,000',\n",
       "  'job_highlights': [{'title': 'Qualifications',\n",
       "    'items': ['4 years of relevant experience with a bachelor’s degree in computer science, engineering, mathematics, or other related discipline',\n",
       "     '(Or a master’s degree and 1 year, a Ph.D. and 0 years)',\n",
       "     'Preference for IAT Level II certification',\n",
       "     'An active secret clearance or higher is REQUIRED']},\n",
       "   {'title': 'Responsibilities',\n",
       "    'items': ['This role requires occasional onsite work',\n",
       "     'The candidate will need to travel to Richmond, Va, on occasion for on-site work',\n",
       "     'Develops the data extraction and preparation processes',\n",
       "     'Runs data quality audits and identifies issues with data collection',\n",
       "     'Implements improvements and fixes to data collection processes',\n",
       "     'Oversees SQL databases that can be large and complex']},\n",
       "   {'title': 'Benefits', 'items': ['Salary - $110,000 - $114,000']}],\n",
       "  'related_links': [{'link': 'https://www.google.com/search?sca_esv=05f85961c74d2d97&q=Echelon+Services,+LLC&sa=X&ved=0ahUKEwj2wbek__aEAxXhM0QIHR1gAbwQmJACCM0N',\n",
       "    'text': 'See web results for Echelon Services, LLC'}],\n",
       "  'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTYysvTqgDiBYzcU3zvHD8cVwROHQ0HPLMW8_lIxnQ&s',\n",
       "  'extensions': ['4 days ago', 'Work from home', 'Full-time'],\n",
       "  'detected_extensions': {'posted_at': '4 days ago',\n",
       "   'schedule_type': 'Full-time',\n",
       "   'work_from_home': True},\n",
       "  'job_id': 'eyJqb2JfdGl0bGUiOiJKciBEYXRhIEFuYWx5dGljcyBFbmdpbmVlciIsImh0aWRvY2lkIjoidEZtbHVpT0NCRFR4UVhYOEFBQUFBQT09IiwiaGwiOiJlbiIsImZjIjoiRXFJQ0N1SUJRVTUxVjJoamF6ZFVaRTF3WlcxNFdtVllaM1ZIVVdoMFpURXhPVE5GYkRsRk9IZHdTalUxUTFsSlZYVmhWazVNVVdWNVNVRkNORkpOTVRBME1IWmlaR2t0UzBsWlJYcHJSazlPWmtWTlFuaDBObE5EV0RsaWMyZ3RXbWRHZDI5U2FVSlpUM28zTkU0eVMwbEZja0UzY1dsWlNrTmZTelJqT0hoWFJEZHdkVWMxY3pkcFYxaHdTRFphZGtaZmNtcGtWVzVsVVdkeWRqZDJOMkpZVGpWeVNsaFRja2M0ZVVvdFUyUm5iVlJ1YUZSZmQwNTNibHBwYVhSUWEwRmlVbmxSU1ZOSGFXMUtaa0pQUTI1RldYSnFSa1poZUhkNGVGWnhiVm8yY1ROYVptZFpaeElYV2paRU1GcGlZbmxEVDBodWExQkpVRzVqUTBZMFFYTWFJa0ZRV0dodE5WbFllRkUwVkhkTlJFcGZkM2xyYjNOS1ZVMXpRMHMwUjNwUmNXYyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzE0IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIExpbmtlZEluIiwibGluayI6Imh0dHBzOi8vd3d3LmxpbmtlZGluLmNvbS9qb2JzL3ZpZXcvanItZGF0YS1hbmFseXRpY3MtZW5naW5lZXItYXQtZWNoZWxvbi1zZXJ2aWNlcy1sbGMtMzg0ODk2MDg5OD91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19'},\n",
       " {'title': 'Sr. Data Engineer',\n",
       "  'company_name': 'Posthaste Labs',\n",
       "  'location': ' Anywhere ',\n",
       "  'via': 'via Glassdoor',\n",
       "  'description': 'About Posthaste Labs:\\n\\nPosthaste Labs is a boutique consulting firm that provides development and data services to VCs and startups. Our focus is on building the highest quality products that will enable our customers to quickly gain traction in the market while ensuring that their code and data ecosystems are robust and able to scale...\\n\\nAbout the role:\\n\\nAs a Sr. Data Engineer with Posthaste Labs, you will be responsible for developing both the business logic as well as technical implementation for the data pipelines that are used by the client to run their operations. The pipelines will be developed using dbt and will need to merge data across several distinct data sources using information that changes across time. This position will be embedded directly with the client in a leading BioTech firm while having autonomy to determine the tools, technologies and processes. You will work directly with the client, shaping requirements, defining timelines and executing on agreed-upon deliverables.\\n\\nThis role will primarily work within Snowflake/dbt, but at times will require the person to be able to implement end-to-end solutions using Python and or Spark. The person must be able to take nebulous requirements and determine which technologies are best suited for which use-cases and be able to implement them themselves.\\n\\nKey Responsibilities:\\n• Entity resolution: Develop matching algorithms that will reconcile data about entities from disparate sources, rank matches and intelligently correlate records together.\\n• Pipeline development: create well-defined dbt models that optimize reusability and performance while providing value for the use-case they’re defined for\\n• Data preparation for modeling: have a firm understanding of the data needs for different ML models that are used for unstructured text classification and be able to clean and curate data sets that can train these models\\n• Measurement: Lead the analytical measurement and efficacy of the entity resolution process as well as creating tooling that surfaces data quality issues early.\\n• Client engagement: Proactively identify gaps, issues and data needs while sharing opinions with client. Lead interactions and projects with clear communication.\\n\\nQualifications and Experience:\\n• 8+ years using SQL / building data pipelines in SQL\\n• 3+ years developing entity resolution algorithms\\n• 2+ years with dbt\\n• 5+ years working with Python, Spark and Snowflake\\n• 3+ years in startups\\n• Proven experience moving analytical workloads into scalable production processes\\n• Highly opinionated on analytical approaches and able to articulate tradeoffs between different methodologies\\n• Able to curate a plan to convert a highly ambiguous project into a structured and well-managed project\\n\\nJob Types: Full-time, Contract\\n\\nPay: $85.00 - $100.00 per hour\\n\\nExpected hours: 40 per week\\n\\nExperience level:\\n• 8 years\\n\\nSchedule:\\n• Monday to Friday\\n\\nExperience:\\n• Spark: 3 years (Required)\\n• dbt: 2 years (Required)\\n• Entity resolution: 3 years (Required)\\n• SQL: 8 years (Required)\\n\\nWork Location: Remote',\n",
       "  'job_highlights': [{'title': 'Qualifications',\n",
       "    'items': ['The person must be able to take nebulous requirements and determine which technologies are best suited for which use-cases and be able to implement them themselves',\n",
       "     '8+ years using SQL / building data pipelines in SQL',\n",
       "     '3+ years developing entity resolution algorithms',\n",
       "     '5+ years working with Python, Spark and Snowflake',\n",
       "     '3+ years in startups',\n",
       "     'Proven experience moving analytical workloads into scalable production processes',\n",
       "     'Highly opinionated on analytical approaches and able to articulate tradeoffs between different methodologies',\n",
       "     'Able to curate a plan to convert a highly ambiguous project into a structured and well-managed project',\n",
       "     'Spark: 3 years (Required)',\n",
       "     'dbt: 2 years (Required)',\n",
       "     'SQL: 8 years (Required)']},\n",
       "   {'title': 'Responsibilities',\n",
       "    'items': ['Data Engineer with Posthaste Labs, you will be responsible for developing both the business logic as well as technical implementation for the data pipelines that are used by the client to run their operations',\n",
       "     'The pipelines will be developed using dbt and will need to merge data across several distinct data sources using information that changes across time',\n",
       "     'This position will be embedded directly with the client in a leading BioTech firm while having autonomy to determine the tools, technologies and processes',\n",
       "     'You will work directly with the client, shaping requirements, defining timelines and executing on agreed-upon deliverables',\n",
       "     'This role will primarily work within Snowflake/dbt, but at times will require the person to be able to implement end-to-end solutions using Python and or Spark',\n",
       "     'Entity resolution: Develop matching algorithms that will reconcile data about entities from disparate sources, rank matches and intelligently correlate records together',\n",
       "     'Pipeline development: create well-defined dbt models that optimize reusability and performance while providing value for the use-case they’re defined for',\n",
       "     'Data preparation for modeling: have a firm understanding of the data needs for different ML models that are used for unstructured text classification and be able to clean and curate data sets that can train these models',\n",
       "     'Measurement: Lead the analytical measurement and efficacy of the entity resolution process as well as creating tooling that surfaces data quality issues early',\n",
       "     'Client engagement: Proactively identify gaps, issues and data needs while sharing opinions with client',\n",
       "     'Lead interactions and projects with clear communication']},\n",
       "   {'title': 'Benefits',\n",
       "    'items': ['Pay: $85.00 - $100.00 per hour',\n",
       "     'Expected hours: 40 per week']}],\n",
       "  'related_links': [{'link': 'https://www.google.com/search?sca_esv=05f85961c74d2d97&q=Posthaste+Labs&sa=X&ved=0ahUKEwj2wbek__aEAxXhM0QIHR1gAbwQmJACCJsO',\n",
       "    'text': 'See web results for Posthaste Labs'}],\n",
       "  'extensions': ['6 days ago',\n",
       "   '85–100 an hour',\n",
       "   'Work from home',\n",
       "   'Full-time and Contractor',\n",
       "   'No degree mentioned'],\n",
       "  'detected_extensions': {'posted_at': '6 days ago',\n",
       "   'schedule_type': 'Full-time and Contractor',\n",
       "   'salary': '85–100 an hour',\n",
       "   'work_from_home': True},\n",
       "  'job_id': 'eyJqb2JfdGl0bGUiOiJTci4gRGF0YSBFbmdpbmVlciIsImh0aWRvY2lkIjoibTRRc0hjMUdoMWtxanJTb0FBQUFBQT09IiwiaGwiOiJlbiIsImZjIjoiRW93Q0Nzd0JRVTUxVjJoamJIVjJSRzg0ZW1SNk0yVXRWeTFqVFVsb1JFZFNlRFZ5ZFhJdFJsQTVlVzlRUkRKWFRsOVVjbGRhTUUwNU9FTndhblpZU214NFkxaGlOV05xTkhaRk5WWjRka1ZyUzNCNWEySm1jMlJPTVZkSmJFeGtaMVV4U20xYWEzaDZMVTl5ZUU4eFVFSktTbTkxZDB0SlprUkVUV3BMWDNsNk5DMXljV2xWZEZSTU1sTk9TWEozUzJwVmRWSTNVa3MxT0MwMGQwcDNVR1pqU214V1JUVkNWazVKUm5ZNGJGOXJkbWxYZWpaNldFTjZYMUF5U0U1V2VUaDJjMVJRY1hSeE1UTk1UVFpUV1U1MUVoZGFOa1F3V21KaWVVTlBTRzVyVUVsUWJtTkRSalJCY3hvaVFWQllhRzAxV25SUloweFBabFJVTmswelNsb3pPSEZOVFV4ME5YbzVPRWQwUVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xNSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBkaXJlY3RseSBvbiBHbGFzc2Rvb3IiLCJsaW5rIjoiaHR0cHM6Ly93d3cuZ2xhc3Nkb29yLmNvbS9qb2ItbGlzdGluZy9zci1kYXRhLWVuZ2luZWVyLXBvc3RoYXN0ZS1sYWJzLUpWX0tPMCwxNl9LRTE3LDMxLmh0bT9qbD0xMDA5MTc5MDE4MTMyXHUwMDI2dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=='},\n",
       " {'title': 'Data Engineer',\n",
       "  'company_name': 'CoxHealth',\n",
       "  'location': '  United States   ',\n",
       "  'via': 'via CoxHealth - Careers',\n",
       "  'description': 'Summary\\n• Best in Class Work Environment\\n• 5x Modern Healthcare Best Places to work...\\n• America’s Greatest Workplaces 2023 – Newsweek\\n• Best Employers for New Grads 2023- Forbes\\n• Greatest Workplace for Women 2023 - Newsweek\\n• Benefits\\n• Robust, fully customizable benefits package including Medical/Vision/Dental and more!\\n• No cost eCare visits\\n• Employer-provided mental health services for employees and eligible family members\\n• Retirement with employer match up to 5%\\n• Tuition discounts and reimbursement available for continuing your education\\n• Free and convenient parking\\n• CoxHealth Fitness Center and Child Care discounts\\n• Onsite delivery for CoxHealth Pharmacies and 1906 Employee Store\\n\\nData Engineer I:\\n\\nJob Summary\\n• The Data Engineer I will be responsible for assisting in the development, testing, and configuration of automated data management solutions. This role requires a foundational understanding of SQL and relational database technologies. The successful candidate will contribute to data processing projects and ensure they are up to date with the latest technologies. Additionally, they will work to interpret business needs into technical solutions and participate in guiding the technical direction of data management systems.\\n\\nJob Requirements\\n• Education\\n• Preferred: Bachelor’s degree in Management Information Systems, Computer Science, Data & Analytics other quantitative discipline or equivalent experience\\n• Experience\\n• Preferred:0-2 years of experience in a data engineering role OR Bachelor’s degree in Management Information Systems, Computer Science, Data & Analytics other quantitative discipline or equivalent experience.\\n• Skills\\n• Deep knowledge of SQL and relational databases.\\n• Familiarity with data ingestion, transformation, and modeling.\\n• Basic understanding of data interfaces and enterprise architecture.\\n• Strong problem-solving abilities.\\n• Excellent communication and collaboration skills.\\n• Detail-oriented with strong organizational skills.\\n• Ability to manage multiple tasks concurrently.\\n• Licensure/Certification/Registration\\n• n.a.\\n\\nData Engineer II:\\n• Job Summary\\n• The Data Engineer II will be instrumental in the architecture, development, and deployment of scalable data management solutions. This role expands on foundational knowledge with a focus on optimizing data processes and integrating complex systems. Candidates will need to demonstrate an intermediate understanding of the data lifecycle and be proactive in adapting to new technologies.\\n• Job Requirements\\n• Education\\n• Required: Bachelor’s degree in Management Information Systems, Computer Science, Data & Analytics or other quantitative discipline or 8 years experience\\n• Experience\\n• Required: 2-5 years of data engineering experience.\\n• Skills\\n• * Proficiency in SQL and database management systems.\\n• Experience with data warehousing solutions.\\n• Skilled in data modeling and ETL processes.\\n• Ability to implement data pipelines and workflows.\\n• Good understanding of cloud services (AWS, Azure, GCP).\\n• Strong analytical and organizational skills.\\n• Ability to lead small projects and guide technical decision-making.\\n• Licensure/Certification/Registration\\n• n.a',\n",
       "  'job_highlights': [{'title': 'Qualifications',\n",
       "    'items': ['Deep knowledge of SQL and relational databases',\n",
       "     'Familiarity with data ingestion, transformation, and modeling',\n",
       "     'Basic understanding of data interfaces and enterprise architecture',\n",
       "     'Strong problem-solving abilities',\n",
       "     'Excellent communication and collaboration skills',\n",
       "     'Detail-oriented with strong organizational skills',\n",
       "     'Ability to manage multiple tasks concurrently',\n",
       "     'Candidates will need to demonstrate an intermediate understanding of the data lifecycle and be proactive in adapting to new technologies',\n",
       "     'Required: Bachelor’s degree in Management Information Systems, Computer Science, Data & Analytics or other quantitative discipline or 8 years experience',\n",
       "     'Required: 2-5 years of data engineering experience',\n",
       "     'Proficiency in SQL and database management systems',\n",
       "     'Experience with data warehousing solutions',\n",
       "     'Skilled in data modeling and ETL processes',\n",
       "     'Ability to implement data pipelines and workflows',\n",
       "     'Good understanding of cloud services (AWS, Azure, GCP)',\n",
       "     'Strong analytical and organizational skills',\n",
       "     'Ability to lead small projects and guide technical decision-making']},\n",
       "   {'title': 'Responsibilities',\n",
       "    'items': ['The Data Engineer I will be responsible for assisting in the development, testing, and configuration of automated data management solutions',\n",
       "     'This role requires a foundational understanding of SQL and relational database technologies',\n",
       "     'The successful candidate will contribute to data processing projects and ensure they are up to date with the latest technologies',\n",
       "     'Additionally, they will work to interpret business needs into technical solutions and participate in guiding the technical direction of data management systems',\n",
       "     'The Data Engineer II will be instrumental in the architecture, development, and deployment of scalable data management solutions',\n",
       "     'This role expands on foundational knowledge with a focus on optimizing data processes and integrating complex systems']},\n",
       "   {'title': 'Benefits',\n",
       "    'items': ['Robust, fully customizable benefits package including Medical/Vision/Dental and more!',\n",
       "     'No cost eCare visits',\n",
       "     'Employer-provided mental health services for employees and eligible family members',\n",
       "     'Retirement with employer match up to 5%',\n",
       "     'Tuition discounts and reimbursement available for continuing your education',\n",
       "     'Free and convenient parking',\n",
       "     'CoxHealth Fitness Center and Child Care discounts']}],\n",
       "  'related_links': [{'link': 'https://www.google.com/search?sca_esv=05f85961c74d2d97&q=CoxHealth&sa=X&ved=0ahUKEwj2wbek__aEAxXhM0QIHR1gAbwQmJACCOoO',\n",
       "    'text': 'See web results for CoxHealth'}],\n",
       "  'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRsBZvj122VhZ0UzzMC8d-3FJndJ6JhYmwSUlKuZOg&s',\n",
       "  'extensions': ['2 days ago',\n",
       "   'Full-time',\n",
       "   'Health insurance',\n",
       "   'Dental insurance'],\n",
       "  'detected_extensions': {'posted_at': '2 days ago',\n",
       "   'schedule_type': 'Full-time'},\n",
       "  'job_id': 'eyJqb2JfdGl0bGUiOiJEYXRhIEVuZ2luZWVyIiwiaHRpZG9jaWQiOiI1TXFSQ1hYN0N0NDg5TU1iQUFBQUFBPT0iLCJobCI6ImVuIiwiZmMiOiJFdmNCQ3JjQlFVNTFWMmhqYTJkNGVuaGhjVlZoU0dZMFNXUjJjakZuVUhkWFoyWTFPRFJmYUhVMWQyNWxkWFp1V0VWME1VcFdWMUJWY0RGbVdtOTZNRUpzZDA1TmJXMUpWRmR3UmtKSFVtWm5SMk5GVW0xZk5YZHBNRVZVT1MxclQyMUxjVGxvZDNOeVJIRnlPREJqVjAwM05YWnJOR0Y1YjJkM2NVaGhVelZQWXpOTlVUVjVRbkptZVRSMVluaFNObm95U3pKQ1lXaE1TemxIVlZKVUxYQTNOMnBXUm1OMGMxRnZha3g1U1VvNVpteGpTV0pvVWkxSFJXMVZFaGRhTmtRd1dtSmllVU5QU0c1clVFbFFibU5EUmpSQmN4b2lRVkJZYUcwMVdtSnlNbUZCY0dkMVRrbEpNVTVzV1RaVVNqbHdkM1YyY1RkeFVRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTYiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgZGlyZWN0bHkgb24gQ294SGVhbHRoIC0gQ2FyZWVycyIsImxpbmsiOiJodHRwczovL2NhcmVlcnMtY294aGVhbHRoLmhjdHNwb3J0YWxzLmNvbS9qb2JzLzE3OTI4MjQtZGF0YS1lbmdpbmVlcj91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_datetime =  datetime.now().strftime(\"%m_%d_%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03_15_2024'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file to ../raw_data/latest_jobs_03_15_2024.json\n"
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = f\"../raw_data/latest_jobs_{current_datetime}.json\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Save to JSON\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(jobs_results, f)\n",
    "    print(f\"Saved file to {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/gsearch_jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>extensions</th>\n",
       "      <th>job_id</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>...</th>\n",
       "      <th>commute_time</th>\n",
       "      <th>salary_pay</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_avg</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "      <th>salary_hourly</th>\n",
       "      <th>salary_yearly</th>\n",
       "      <th>salary_standardized</th>\n",
       "      <th>description_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Chloeta</td>\n",
       "      <td>Oklahoma City, OK</td>\n",
       "      <td>via ZipRecruiter</td>\n",
       "      <td>Job Summary: The Data Analyst oversees data pr...</td>\n",
       "      <td>['21 hours ago', 'Full-time', 'Health insuranc...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['r', 'python']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Junior Data Analyst/Scientist Role - Contract ...</td>\n",
       "      <td>Upwork</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via Upwork</td>\n",
       "      <td>Company\\n\\nThe TAC Index provides independent,...</td>\n",
       "      <td>['17 hours ago', 'Work from home', 'Contractor...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJKdW5pb3IgRGF0YSBBbmFseXN0L1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['matplotlib', 'pandas', 'mysql', 'matlab', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>ATC</td>\n",
       "      <td>United States</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Job Title: Entry Level Business Analyst / Prod...</td>\n",
       "      <td>['12 hours ago', 'Full-time', 'Health insurance']</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guidehouse</td>\n",
       "      <td>Topeka, KS</td>\n",
       "      <td>via Nexxt</td>\n",
       "      <td>Job Family :\\n\\nData Science &amp; Analysis (Digit...</td>\n",
       "      <td>['10 hours ago', 'Full-time', 'Health insuranc...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...</td>\n",
       "      <td>https://encrypted-tbn0.gstatic.com/images?q=tb...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['powerpoint', 'perl', 'word', 'power_bi', 'ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>AnMed Health LLC</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>AnMed is a dynamic, comprehensive health syste...</td>\n",
       "      <td>['18 hours ago', 'Work from home', 'Part-time'...</td>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                              title  \\\n",
       "0           0      0                                       Data Analyst   \n",
       "1           1      1  Junior Data Analyst/Scientist Role - Contract ...   \n",
       "2           2      2                                       Data Analyst   \n",
       "3           3      3                                       Data Analyst   \n",
       "4           4      4                                       Data Analyst   \n",
       "\n",
       "       company_name                location               via  \\\n",
       "0           Chloeta    Oklahoma City, OK     via ZipRecruiter   \n",
       "1            Upwork               Anywhere         via Upwork   \n",
       "2               ATC        United States         via LinkedIn   \n",
       "3        Guidehouse           Topeka, KS            via Nexxt   \n",
       "4  AnMed Health LLC               Anywhere       via LinkedIn   \n",
       "\n",
       "                                         description  \\\n",
       "0  Job Summary: The Data Analyst oversees data pr...   \n",
       "1  Company\\n\\nThe TAC Index provides independent,...   \n",
       "2  Job Title: Entry Level Business Analyst / Prod...   \n",
       "3  Job Family :\\n\\nData Science & Analysis (Digit...   \n",
       "4  AnMed is a dynamic, comprehensive health syste...   \n",
       "\n",
       "                                          extensions  \\\n",
       "0  ['21 hours ago', 'Full-time', 'Health insuranc...   \n",
       "1  ['17 hours ago', 'Work from home', 'Contractor...   \n",
       "2  ['12 hours ago', 'Full-time', 'Health insurance']   \n",
       "3  ['10 hours ago', 'Full-time', 'Health insuranc...   \n",
       "4  ['18 hours ago', 'Work from home', 'Part-time'...   \n",
       "\n",
       "                                              job_id  \\\n",
       "0  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...   \n",
       "1  eyJqb2JfdGl0bGUiOiJKdW5pb3IgRGF0YSBBbmFseXN0L1...   \n",
       "2  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...   \n",
       "3  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...   \n",
       "4  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QiLCJodGlkb2...   \n",
       "\n",
       "                                           thumbnail  ... commute_time  \\\n",
       "0                                                NaN  ...          NaN   \n",
       "1                                                NaN  ...          NaN   \n",
       "2  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...          NaN   \n",
       "3  https://encrypted-tbn0.gstatic.com/images?q=tb...  ...          NaN   \n",
       "4                                                NaN  ...          NaN   \n",
       "\n",
       "  salary_pay salary_rate salary_avg salary_min salary_max salary_hourly  \\\n",
       "0        NaN         NaN        NaN        NaN        NaN           NaN   \n",
       "1        NaN         NaN        NaN        NaN        NaN           NaN   \n",
       "2        NaN         NaN        NaN        NaN        NaN           NaN   \n",
       "3        NaN         NaN        NaN        NaN        NaN           NaN   \n",
       "4        NaN         NaN        NaN        NaN        NaN           NaN   \n",
       "\n",
       "   salary_yearly salary_standardized  \\\n",
       "0            NaN                 NaN   \n",
       "1            NaN                 NaN   \n",
       "2            NaN                 NaN   \n",
       "3            NaN                 NaN   \n",
       "4            NaN                 NaN   \n",
       "\n",
       "                                  description_tokens  \n",
       "0                                    ['r', 'python']  \n",
       "1  ['matplotlib', 'pandas', 'mysql', 'matlab', 'p...  \n",
       "2                                                 []  \n",
       "3  ['powerpoint', 'perl', 'word', 'power_bi', 'ta...  \n",
       "4                                                 []  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
